{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdejang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dejang/loop_tool_env/loop_tool_service/wandb/run-20220629_145412-2wnj7kv5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dejang/loop_tool/runs/2wnj7kv5\" target=\"_blank\">rural-disco-5</a></strong> to <a href=\"https://wandb.ai/dejang/loop_tool\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dejang/loop_tool/runs/2wnj7kv5?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f762faaa0a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install compiler_gym 'ray[default,rllib]' &>/dev/null || echo \"Install failed!\"\n",
    "\n",
    "import compiler_gym\n",
    "import ray\n",
    "\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from compiler_gym.wrappers import ConstrainedCommandline, TimeLimit\n",
    "from ray import tune\n",
    "from itertools import islice\n",
    "from compiler_gym.wrappers import CycleOverBenchmarks\n",
    "from compiler_gym.util.registration import register\n",
    "\n",
    "import loop_tool_service\n",
    "\n",
    "from service_py.datasets import loop_tool_dataset\n",
    "from service_py.rewards import flops_loop_nest_reward, flops_reward, runtime_reward\n",
    "import wandb\n",
    "wandb.init(project=\"loop_tool\", entity=\"dejang\", sync_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env() -> compiler_gym.envs.CompilerEnv:\n",
    "    \"\"\"Make the reinforcement learning environment for this experiment.\"\"\"\n",
    "    \n",
    "    env = loop_tool_service.make(\n",
    "        \"loop_tool_env-v0\",\n",
    "        observation_space=\"stride_tensor\",\n",
    "        reward_space=\"flops_loop_nest_tensor\",\n",
    "        # reward_space=\"runtime\",\n",
    "    )\n",
    "\n",
    "    env = TimeLimit(env, max_episode_steps=10)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: NamedDiscrete([up, down, swap_up, swap_down])\n",
      "Observation space: Box([[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]], [[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      "  inf inf inf inf inf inf inf inf inf inf inf inf inf inf]], (1, 32), float32)\n",
      "Reward space: flops_loop_nest_tensor\n"
     ]
    }
   ],
   "source": [
    "with make_env() as env:\n",
    "    print(\"Action space:\", env.action_space)\n",
    "    print(\"Observation space:\", env.observation_space)\n",
    "    print(\"Reward space:\", env.reward_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of benchmarks for training: 1\n",
      "Number of benchmarks for testing: 1\n"
     ]
    }
   ],
   "source": [
    "with make_env() as env:\n",
    "    # The two datasets we will be using:\n",
    "    lt_dataset = env.datasets[\"loop_tool_simple-v0\"]\n",
    "    # train_benchmarks = list(islice(lt_dataset.benchmarks(), 1))\n",
    "    # test_benchmarks = list(islice(lt_dataset.benchmarks(), 2))\n",
    "    \n",
    "    bench = [\"benchmark://loop_tool_simple-v0/simple\"]\n",
    "            #  \"benchmark://loop_tool_simple-v0/mm128\", \n",
    "            #  \"benchmark://loop_tool_simple-v0/mm\"] \n",
    "\n",
    "    train_benchmarks = bench\n",
    "    test_benchmarks = bench\n",
    "\n",
    "print(\"Number of benchmarks for training:\", len(train_benchmarks))\n",
    "print(\"Number of benchmarks for testing:\", len(test_benchmarks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_env(*args) -> compiler_gym.envs.CompilerEnv:\n",
    "    \"\"\"Make a reinforcement learning environment that cycles over the\n",
    "    set of training benchmarks in use.\n",
    "    \"\"\"\n",
    "    del args  # Unused env_config argument passed by ray\n",
    "    return CycleOverBenchmarks(make_env(), train_benchmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      " for n_5625 in 128 : L1  \n",
      "  for k_5587 in 128 : L2  \n",
      "   %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "   %3[m_5586, n_5625] <- add(%2)  \n",
      "  %4[m_5586, n_5625] <- write(%3)  \n",
      "\n",
      "benchmark://loop_tool_simple-v0/simple\n",
      "for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      " for n_5625 in 128 : L1  \n",
      "  for k_5587 in 128 : L2  \n",
      "   %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "   %3[m_5586, n_5625] <- add(%2)  \n",
      "  %4[m_5586, n_5625] <- write(%3)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0629 14:54:21.600706 139853277578816 example_service.py:249] CRITICAL - \n",
      "\n",
      "Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145420-561928-1422\n",
      "\n",
      "E0629 14:54:21.708813 139853277578816 example_service.py:249] CRITICAL - \n",
      "\n",
      "Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145420-561928-1422\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark://loop_tool_simple-v0/simple\n"
     ]
    }
   ],
   "source": [
    "with make_training_env() as env:\n",
    "    env.reset()\n",
    "    print(env.benchmark)\n",
    "    env.reset()\n",
    "    print(env.benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      " for n_5625 in 128 : L1  \n",
      "  for k_5587 in 128 : L2  \n",
      "   %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "   %3[m_5586, n_5625] <- add(%2)  \n",
      "  %4[m_5586, n_5625] <- write(%3)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0629 14:54:23.185833 140463474468416 example_service.py:249] CRITICAL - \n",
      "\n",
      "Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145422-151049-0111\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2113536.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0., 2097280.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = make_training_env()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2113536.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0., 2097280.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.]], dtype=float32),\n",
       " -2144890833.176635,\n",
       " False,\n",
       " {'action_had_no_effect': True, 'new_action_space': False})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init(include_dashboard=False, ignore_reinit_error=True)\n",
    "\n",
    "tune.register_env(\"compiler_gym\", make_training_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ray import tune\n",
    "from ray.tune import Stopper\n",
    "\n",
    "class TimeStopper(Stopper):\n",
    "    def __init__(self):\n",
    "        self._start = time.time()\n",
    "        self._deadline = 1\n",
    "\n",
    "    def __call__(self, trial_id, result):\n",
    "        return False\n",
    "\n",
    "    def stop_all(self):\n",
    "        return time.time() - self._start > self._deadline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26/PPOTrainer_compiler_gym_e618f_00000_0_0=20,1=20_2022-06-29_14-54-26\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747313)\u001b[0m 2022-06-29 14:54:30,987\tINFO trainer.py:2332 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747313)\u001b[0m 2022-06-29 14:54:31,194\tINFO ppo.py:414 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747313)\u001b[0m 2022-06-29 14:54:31,194\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m E0629 14:54:36.581149 139877103203904 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145435-554058-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:54:39 (running for 00:00:12.53)<br>Memory usage on this node: 16.0/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>RUNNING </td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747313)\u001b[0m 2022-06-29 14:54:39,220\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26/PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m E0629 14:54:39.249601 139877103203904 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145435-554058-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747508)\u001b[0m 2022-06-29 14:54:43,941\tINFO trainer.py:2332 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747508)\u001b[0m 2022-06-29 14:54:44,156\tINFO ppo.py:414 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747508)\u001b[0m 2022-06-29 14:54:44,156\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m E0629 14:54:49.557003 140131922155072 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145448-530599-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:54:52 (running for 00:00:25.52)<br>Memory usage on this node: 16.8/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (2 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>RUNNING </td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>RUNNING </td><td>100.37.253.28:2747508</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26/PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747508)\u001b[0m 2022-06-29 14:54:52,206\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m E0629 14:54:52.235604 140131922155072 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145448-530599-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747808)\u001b[0m 2022-06-29 14:54:56,714\tINFO trainer.py:2332 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747808)\u001b[0m 2022-06-29 14:54:56,918\tINFO ppo.py:414 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747808)\u001b[0m 2022-06-29 14:54:56,918\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m E0629 14:55:02.382861 139931601782336 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145501-347265-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=2747808)\u001b[0m 2022-06-29 14:55:05,075\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:55:05 (running for 00:00:38.39)<br>Memory usage on this node: 17.8/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (1 PENDING, 3 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>RUNNING </td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>RUNNING </td><td>100.37.253.28:2747508</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>RUNNING </td><td>100.37.253.28:2747808</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26/PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m E0629 14:55:05.103601 139931601782336 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145501-347265-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=2748095)\u001b[0m 2022-06-29 14:55:09,614\tINFO trainer.py:2332 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2748095)\u001b[0m 2022-06-29 14:55:09,829\tINFO ppo.py:414 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2748095)\u001b[0m 2022-06-29 14:55:09,829\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m E0629 14:55:15.230710 139696420152896 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145514-204240-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:55:17 (running for 00:00:51.22)<br>Memory usage on this node: 18.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>RUNNING </td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>RUNNING </td><td>100.37.253.28:2747508</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>RUNNING </td><td>100.37.253.28:2747808</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>RUNNING </td><td>100.37.253.28:2748095</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_compiler_gym_e618f_00002:\n",
      "  agent_timesteps_total: 5\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5\n",
      "    num_agent_steps_trained: 5\n",
      "    num_env_steps_sampled: 5\n",
      "    num_env_steps_trained: 5\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-08\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 209062bd7460491db9c3ab2ea497b237\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3860167264938354\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00022437745064962655\n",
      "          model: {}\n",
      "          policy_loss: -0.014704064466059208\n",
      "          total_loss: 1.9868420362472534\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0015010833740234\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 5\n",
      "    num_agent_steps_trained: 5\n",
      "    num_env_steps_sampled: 5\n",
      "    num_env_steps_trained: 5\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 5\n",
      "  num_agent_steps_trained: 5\n",
      "  num_env_steps_sampled: 5\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 5\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.71666666666667\n",
      "    ram_util_percent: 58.333333333333336\n",
      "  pid: 2747808\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: .nan\n",
      "    episode_media: {}\n",
      "    episode_reward_max: .nan\n",
      "    episode_reward_mean: .nan\n",
      "    episode_reward_min: .nan\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths: []\n",
      "      episode_reward: []\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf: {}\n",
      "  time_since_restore: 3.558126449584961\n",
      "  time_this_iter_s: 3.558126449584961\n",
      "  time_total_s: 3.558126449584961\n",
      "  timers:\n",
      "    learn_throughput: 24.37\n",
      "    learn_time_ms: 205.167\n",
      "    load_throughput: 17418.206\n",
      "    load_time_ms: 0.287\n",
      "    training_iteration_time_ms: 3555.691\n",
      "    update_time_ms: 1.649\n",
      "  timestamp: 1656528908\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5\n",
      "  training_iteration: 1\n",
      "  trial_id: e618f_00002\n",
      "  warmup_time: 8.369242429733276\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=2748095)\u001b[0m 2022-06-29 14:55:17,905\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:55:17 (running for 00:00:51.27)<br>Memory usage on this node: 18.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>RUNNING </td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>RUNNING </td><td>100.37.253.28:2747508</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>RUNNING </td><td>100.37.253.28:2747808</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.55813</td><td style=\"text-align: right;\">   5</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">               nan</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>RUNNING </td><td>100.37.253.28:2748095</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m cc1: fatal error: /tmp/fn_69.c: No such file or directory\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m compilation terminated.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m E0629 14:55:17.931110 139696420152896 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145514-204240-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_compiler_gym_e618f_00001:\n",
      "  agent_timesteps_total: 5\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5\n",
      "    num_agent_steps_trained: 5\n",
      "    num_env_steps_sampled: 5\n",
      "    num_env_steps_trained: 5\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-54-55\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 660a5503437348b3848016617fefbbd7\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3862144947052002\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 5.757127291872166e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.0075375535525381565\n",
      "          total_loss: 1.992805004119873\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.000330924987793\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 5\n",
      "    num_agent_steps_trained: 5\n",
      "    num_env_steps_sampled: 5\n",
      "    num_env_steps_trained: 5\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 5\n",
      "  num_agent_steps_trained: 5\n",
      "  num_env_steps_sampled: 5\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 5\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.45\n",
      "    ram_util_percent: 55.400000000000006\n",
      "  pid: 2747508\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: .nan\n",
      "    episode_media: {}\n",
      "    episode_reward_max: .nan\n",
      "    episode_reward_mean: .nan\n",
      "    episode_reward_min: .nan\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths: []\n",
      "      episode_reward: []\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf: {}\n",
      "  time_since_restore: 3.5679571628570557\n",
      "  time_this_iter_s: 3.5679571628570557\n",
      "  time_total_s: 3.5679571628570557\n",
      "  timers:\n",
      "    learn_throughput: 24.329\n",
      "    learn_time_ms: 205.512\n",
      "    load_throughput: 33288.127\n",
      "    load_time_ms: 0.15\n",
      "    training_iteration_time_ms: 3565.591\n",
      "    update_time_ms: 1.862\n",
      "  timestamp: 1656528895\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5\n",
      "  training_iteration: 1\n",
      "  trial_id: e618f_00001\n",
      "  warmup_time: 8.27396011352539\n",
      "  \n",
      "Result for PPOTrainer_compiler_gym_e618f_00000:\n",
      "  agent_timesteps_total: 5\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5\n",
      "    num_agent_steps_trained: 5\n",
      "    num_env_steps_sampled: 5\n",
      "    num_env_steps_trained: 5\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-54-42\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: f88dfa7df9ca45168f205a8ba4639621\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3862744569778442\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 7.05513812135905e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.008253732696175575\n",
      "          total_loss: 1.9928594827651978\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.001099109649658\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 5\n",
      "    num_agent_steps_trained: 5\n",
      "    num_env_steps_sampled: 5\n",
      "    num_env_steps_trained: 5\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 5\n",
      "  num_agent_steps_trained: 5\n",
      "  num_env_steps_sampled: 5\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 5\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.9\n",
      "    ram_util_percent: 52.199999999999996\n",
      "  pid: 2747313\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: .nan\n",
      "    episode_media: {}\n",
      "    episode_reward_max: .nan\n",
      "    episode_reward_mean: .nan\n",
      "    episode_reward_min: .nan\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths: []\n",
      "      episode_reward: []\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf: {}\n",
      "  time_since_restore: 3.51780366897583\n",
      "  time_this_iter_s: 3.51780366897583\n",
      "  time_total_s: 3.51780366897583\n",
      "  timers:\n",
      "    learn_throughput: 21.475\n",
      "    learn_time_ms: 232.832\n",
      "    load_throughput: 13706.876\n",
      "    load_time_ms: 0.365\n",
      "    training_iteration_time_ms: 3515.228\n",
      "    update_time_ms: 2.089\n",
      "  timestamp: 1656528882\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5\n",
      "  training_iteration: 1\n",
      "  trial_id: e618f_00000\n",
      "  warmup_time: 8.240801334381104\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m E0629 14:55:20.743337 139931601782336 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145501-347265-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m E0629 14:55:20.777571 139877103203904 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145435-554058-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m E0629 14:55:20.924558 140131922155072 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145448-530599-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  2\n",
      "Result for PPOTrainer_compiler_gym_e618f_00003:\n",
      "  agent_timesteps_total: 5\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5\n",
      "    num_agent_steps_trained: 5\n",
      "    num_env_steps_sampled: 5\n",
      "    num_env_steps_trained: 5\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-21\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 20a823e5d640460e8655afcd4af39a4b\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3861228227615356\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00015629206609446555\n",
      "          model: {}\n",
      "          policy_loss: -0.012322903610765934\n",
      "          total_loss: 1.987752079963684\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0000433921813965\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 5\n",
      "    num_agent_steps_trained: 5\n",
      "    num_env_steps_sampled: 5\n",
      "    num_env_steps_trained: 5\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 5\n",
      "  num_agent_steps_trained: 5\n",
      "  num_env_steps_sampled: 5\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 5\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.08\n",
      "    ram_util_percent: 60.48\n",
      "  pid: 2748095\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: .nan\n",
      "    episode_media: {}\n",
      "    episode_reward_max: .nan\n",
      "    episode_reward_mean: .nan\n",
      "    episode_reward_min: .nan\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths: []\n",
      "      episode_reward: []\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf: {}\n",
      "  time_since_restore: 3.451291561126709\n",
      "  time_this_iter_s: 3.451291561126709\n",
      "  time_total_s: 3.451291561126709\n",
      "  timers:\n",
      "    learn_throughput: 24.414\n",
      "    learn_time_ms: 204.804\n",
      "    load_throughput: 14423.329\n",
      "    load_time_ms: 0.347\n",
      "    training_iteration_time_ms: 3449.15\n",
      "    update_time_ms: 2.44\n",
      "  timestamp: 1656528921\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5\n",
      "  training_iteration: 1\n",
      "  trial_id: e618f_00003\n",
      "  warmup_time: 8.29993724822998\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  4\n",
      "Result for PPOTrainer_compiler_gym_e618f_00002:\n",
      "  agent_timesteps_total: 15\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15\n",
      "    num_agent_steps_trained: 15\n",
      "    num_env_steps_sampled: 15\n",
      "    num_env_steps_trained: 15\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-23\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2116393153.4729571\n",
      "  episode_reward_mean: -2116393153.4729571\n",
      "  episode_reward_min: -2116393153.4729571\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1\n",
      "  experiment_id: 209062bd7460491db9c3ab2ea497b237\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.05000000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3859407901763916\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 9.877932461677119e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.008973180316388607\n",
      "          total_loss: 7.335625171661377\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 7.344594478607178\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 15\n",
      "    num_agent_steps_trained: 15\n",
      "    num_env_steps_sampled: 15\n",
      "    num_env_steps_trained: 15\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 15\n",
      "  num_agent_steps_trained: 15\n",
      "  num_env_steps_sampled: 15\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 15\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.225\n",
      "    ram_util_percent: 60.5\n",
      "  pid: 2747808\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17887895757501776\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 551.4592040668834\n",
      "    mean_inference_ms: 4.026673056862571\n",
      "    mean_raw_obs_processing_ms: 10.103854266079988\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2116393153.4729571\n",
      "    episode_reward_mean: -2116393153.4729571\n",
      "    episode_reward_min: -2116393153.4729571\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2116393153.4729571\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17887895757501776\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 551.4592040668834\n",
      "      mean_inference_ms: 4.026673056862571\n",
      "      mean_raw_obs_processing_ms: 10.103854266079988\n",
      "  time_since_restore: 9.138229370117188\n",
      "  time_this_iter_s: 2.6316630840301514\n",
      "  time_total_s: 9.138229370117188\n",
      "  timers:\n",
      "    learn_throughput: 54.148\n",
      "    learn_time_ms: 92.34\n",
      "    load_throughput: 16513.008\n",
      "    load_time_ms: 0.303\n",
      "    training_iteration_time_ms: 3042.838\n",
      "    update_time_ms: 1.861\n",
      "  timestamp: 1656528923\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15\n",
      "  training_iteration: 3\n",
      "  trial_id: e618f_00002\n",
      "  warmup_time: 8.369242429733276\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:55:23 (running for 00:00:56.90)<br>Memory usage on this node: 18.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">       reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>RUNNING </td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         6.43162</td><td style=\"text-align: right;\">  10</td><td style=\"text-align: right;\"> -2.11297e+09</td><td style=\"text-align: right;\">        -2.11297e+09</td><td style=\"text-align: right;\">        -2.11297e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>RUNNING </td><td>100.37.253.28:2747508</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         6.65794</td><td style=\"text-align: right;\">  10</td><td style=\"text-align: right;\"> -2.11386e+09</td><td style=\"text-align: right;\">        -2.11386e+09</td><td style=\"text-align: right;\">        -2.11386e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>RUNNING </td><td>100.37.253.28:2747808</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         9.13823</td><td style=\"text-align: right;\">  15</td><td style=\"text-align: right;\"> -2.11639e+09</td><td style=\"text-align: right;\">        -2.11639e+09</td><td style=\"text-align: right;\">        -2.11639e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>RUNNING </td><td>100.37.253.28:2748095</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.45129</td><td style=\"text-align: right;\">   5</td><td style=\"text-align: right;\">nan          </td><td style=\"text-align: right;\">       nan          </td><td style=\"text-align: right;\">       nan          </td><td style=\"text-align: right;\">               nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_compiler_gym_e618f_00000:\n",
      "  agent_timesteps_total: 15\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15\n",
      "    num_agent_steps_trained: 15\n",
      "    num_env_steps_sampled: 15\n",
      "    num_env_steps_trained: 15\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-23\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2112968590.5859597\n",
      "  episode_reward_mean: -2112968590.5859597\n",
      "  episode_reward_min: -2112968590.5859597\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1\n",
      "  experiment_id: f88dfa7df9ca45168f205a8ba4639621\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.05000000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3861362934112549\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.499393667676486e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.004924063570797443\n",
      "          total_loss: 9.995076179504395\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 10.0\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 15\n",
      "    num_agent_steps_trained: 15\n",
      "    num_env_steps_sampled: 15\n",
      "    num_env_steps_trained: 15\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 15\n",
      "  num_agent_steps_trained: 15\n",
      "  num_env_steps_sampled: 15\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 15\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.35\n",
      "    ram_util_percent: 60.5\n",
      "  pid: 2747313\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17547607421875\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 541.7463345961137\n",
      "    mean_inference_ms: 3.551851619373668\n",
      "    mean_raw_obs_processing_ms: 10.282798246903853\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2112968590.5859597\n",
      "    episode_reward_mean: -2112968590.5859597\n",
      "    episode_reward_min: -2112968590.5859597\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2112968590.5859597\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17547607421875\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 541.7463345961137\n",
      "      mean_inference_ms: 3.551851619373668\n",
      "      mean_raw_obs_processing_ms: 10.282798246903853\n",
      "  time_since_restore: 9.145730257034302\n",
      "  time_this_iter_s: 2.7141060829162598\n",
      "  time_total_s: 9.145730257034302\n",
      "  timers:\n",
      "    learn_throughput: 49.114\n",
      "    learn_time_ms: 101.803\n",
      "    load_throughput: 22485.547\n",
      "    load_time_ms: 0.222\n",
      "    training_iteration_time_ms: 3044.954\n",
      "    update_time_ms: 1.802\n",
      "  timestamp: 1656528923\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15\n",
      "  training_iteration: 3\n",
      "  trial_id: e618f_00000\n",
      "  warmup_time: 8.240801334381104\n",
      "  \n",
      "Result for PPOTrainer_compiler_gym_e618f_00001:\n",
      "  agent_timesteps_total: 15\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15\n",
      "    num_agent_steps_trained: 15\n",
      "    num_env_steps_sampled: 15\n",
      "    num_env_steps_trained: 15\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-23\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2113860984.255222\n",
      "  episode_reward_mean: -2113860984.255222\n",
      "  episode_reward_min: -2113860984.255222\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1\n",
      "  experiment_id: 660a5503437348b3848016617fefbbd7\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.05000000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3861299753189087\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.4684615709702484e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.004673521034419537\n",
      "          total_loss: 6.478681564331055\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 6.4833550453186035\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 15\n",
      "    num_agent_steps_trained: 15\n",
      "    num_env_steps_sampled: 15\n",
      "    num_env_steps_trained: 15\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 15\n",
      "  num_agent_steps_trained: 15\n",
      "  num_env_steps_sampled: 15\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 15\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.775000000000006\n",
      "    ram_util_percent: 60.5\n",
      "  pid: 2747508\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15824491327459161\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 564.1112544319847\n",
      "    mean_inference_ms: 3.8465586575594815\n",
      "    mean_raw_obs_processing_ms: 10.189359838312322\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2113860984.255222\n",
      "    episode_reward_mean: -2113860984.255222\n",
      "    episode_reward_min: -2113860984.255222\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2113860984.255222\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.15824491327459161\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 564.1112544319847\n",
      "      mean_inference_ms: 3.8465586575594815\n",
      "      mean_raw_obs_processing_ms: 10.189359838312322\n",
      "  time_since_restore: 9.39007019996643\n",
      "  time_this_iter_s: 2.7321295738220215\n",
      "  time_total_s: 9.39007019996643\n",
      "  timers:\n",
      "    learn_throughput: 52.411\n",
      "    learn_time_ms: 95.401\n",
      "    load_throughput: 30247.385\n",
      "    load_time_ms: 0.165\n",
      "    training_iteration_time_ms: 3126.068\n",
      "    update_time_ms: 2.103\n",
      "  timestamp: 1656528923\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15\n",
      "  training_iteration: 3\n",
      "  trial_id: e618f_00001\n",
      "  warmup_time: 8.27396011352539\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for k_5587 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for k_5587 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for k_5587 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m E0629 14:55:24.286224 139696420152896 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145514-204240-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for k_5587 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for k_5587 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for k_5587 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for k_5587 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for m_5586 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  7\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m E0629 14:55:25.865138 139931601782336 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145501-347265-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for k_5587 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for m_5586 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  7\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m E0629 14:55:25.993272 139877103203904 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145435-554058-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for k_5587 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for m_5586 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  7\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m E0629 14:55:26.224525 140131922155072 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145448-530599-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  4\n",
      "Result for PPOTrainer_compiler_gym_e618f_00003:\n",
      "  agent_timesteps_total: 15\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15\n",
      "    num_agent_steps_trained: 15\n",
      "    num_env_steps_sampled: 15\n",
      "    num_env_steps_trained: 15\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-27\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2113787478.0579987\n",
      "  episode_reward_mean: -2113787478.0579987\n",
      "  episode_reward_min: -2113787478.0579987\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1\n",
      "  experiment_id: 20a823e5d640460e8655afcd4af39a4b\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.05000000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3858883380889893\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 8.515702211298048e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.00840438436716795\n",
      "          total_loss: 6.20708703994751\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 6.215487003326416\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 15\n",
      "    num_agent_steps_trained: 15\n",
      "    num_env_steps_sampled: 15\n",
      "    num_env_steps_trained: 15\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 15\n",
      "  num_agent_steps_trained: 15\n",
      "  num_env_steps_sampled: 15\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 15\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.37499999999999\n",
      "    ram_util_percent: 60.525\n",
      "  pid: 2748095\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1587434248490767\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 549.4254068894819\n",
      "    mean_inference_ms: 3.972075202248313\n",
      "    mean_raw_obs_processing_ms: 10.34910028631037\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2113787478.0579987\n",
      "    episode_reward_mean: -2113787478.0579987\n",
      "    episode_reward_min: -2113787478.0579987\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2113787478.0579987\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1587434248490767\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 549.4254068894819\n",
      "      mean_inference_ms: 3.972075202248313\n",
      "      mean_raw_obs_processing_ms: 10.34910028631037\n",
      "  time_since_restore: 9.256107330322266\n",
      "  time_this_iter_s: 2.777031183242798\n",
      "  time_total_s: 9.256107330322266\n",
      "  timers:\n",
      "    learn_throughput: 54.03\n",
      "    learn_time_ms: 92.542\n",
      "    load_throughput: 20446.721\n",
      "    load_time_ms: 0.245\n",
      "    training_iteration_time_ms: 3081.837\n",
      "    update_time_ms: 1.967\n",
      "  timestamp: 1656528927\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15\n",
      "  training_iteration: 3\n",
      "  trial_id: e618f_00003\n",
      "  warmup_time: 8.29993724822998\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for k_5587 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for k_5587 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for k_5587 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for m_5586 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  7\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  5\n",
      "Result for PPOTrainer_compiler_gym_e618f_00002:\n",
      "  agent_timesteps_total: 25\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 25\n",
      "    num_agent_steps_trained: 25\n",
      "    num_env_steps_sampled: 25\n",
      "    num_env_steps_trained: 25\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-29\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2071212138.4261434\n",
      "  episode_reward_mean: -2093802645.9495502\n",
      "  episode_reward_min: -2116393153.4729571\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 2\n",
      "  experiment_id: 209062bd7460491db9c3ab2ea497b237\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.012500000186264515\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3845984935760498\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0002899089886341244\n",
      "          model: {}\n",
      "          policy_loss: -0.01872572861611843\n",
      "          total_loss: 1.9846516847610474\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.003373861312866\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 25\n",
      "    num_agent_steps_trained: 25\n",
      "    num_env_steps_sampled: 25\n",
      "    num_env_steps_trained: 25\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 25\n",
      "  num_agent_steps_trained: 25\n",
      "  num_env_steps_sampled: 25\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 25\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.480000000000004\n",
      "    ram_util_percent: 60.5\n",
      "  pid: 2747808\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17888618238044507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 535.3944157109116\n",
      "    mean_inference_ms: 3.32271433495856\n",
      "    mean_raw_obs_processing_ms: 10.300036632653438\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2071212138.4261434\n",
      "    episode_reward_mean: -2093802645.9495502\n",
      "    episode_reward_min: -2116393153.4729571\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2116393153.4729571\n",
      "      - -2071212138.4261434\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17888618238044507\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 535.3944157109116\n",
      "      mean_inference_ms: 3.32271433495856\n",
      "      mean_raw_obs_processing_ms: 10.300036632653438\n",
      "  time_since_restore: 15.084923028945923\n",
      "  time_this_iter_s: 3.5143065452575684\n",
      "  time_total_s: 15.084923028945923\n",
      "  timers:\n",
      "    learn_throughput: 68.039\n",
      "    learn_time_ms: 73.487\n",
      "    load_throughput: 19870.684\n",
      "    load_time_ms: 0.252\n",
      "    training_iteration_time_ms: 3013.603\n",
      "    update_time_ms: 1.96\n",
      "  timestamp: 1656528929\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25\n",
      "  training_iteration: 5\n",
      "  trial_id: e618f_00002\n",
      "  warmup_time: 8.369242429733276\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m E0629 14:55:29.612460 139696420152896 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145514-204240-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:55:29 (running for 00:01:03.04)<br>Memory usage on this node: 18.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">      reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>RUNNING </td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        11.5668 </td><td style=\"text-align: right;\">  20</td><td style=\"text-align: right;\">-2.08405e+09</td><td style=\"text-align: right;\">        -2.05512e+09</td><td style=\"text-align: right;\">        -2.11297e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>RUNNING </td><td>100.37.253.28:2747508</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        11.8628 </td><td style=\"text-align: right;\">  20</td><td style=\"text-align: right;\">-2.08232e+09</td><td style=\"text-align: right;\">        -2.05077e+09</td><td style=\"text-align: right;\">        -2.11386e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>RUNNING </td><td>100.37.253.28:2747808</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        15.0849 </td><td style=\"text-align: right;\">  25</td><td style=\"text-align: right;\">-2.0938e+09 </td><td style=\"text-align: right;\">        -2.07121e+09</td><td style=\"text-align: right;\">        -2.11639e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>RUNNING </td><td>100.37.253.28:2748095</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         9.25611</td><td style=\"text-align: right;\">  15</td><td style=\"text-align: right;\">-2.11379e+09</td><td style=\"text-align: right;\">        -2.11379e+09</td><td style=\"text-align: right;\">        -2.11379e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_compiler_gym_e618f_00000:\n",
      "  agent_timesteps_total: 25\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 25\n",
      "    num_agent_steps_trained: 25\n",
      "    num_env_steps_sampled: 25\n",
      "    num_env_steps_trained: 25\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-29\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2055122685.2196105\n",
      "  episode_reward_mean: -2084045637.902785\n",
      "  episode_reward_min: -2112968590.5859597\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 2\n",
      "  experiment_id: f88dfa7df9ca45168f205a8ba4639621\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.012500000186264515\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3854135274887085\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 9.544456406729296e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.01059736218303442\n",
      "          total_loss: 1.9911834001541138\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.001779794692993\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 25\n",
      "    num_agent_steps_trained: 25\n",
      "    num_env_steps_sampled: 25\n",
      "    num_env_steps_trained: 25\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 25\n",
      "  num_agent_steps_trained: 25\n",
      "  num_env_steps_sampled: 25\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 25\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.46666666666666\n",
      "    ram_util_percent: 60.5\n",
      "  pid: 2747313\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1655079069591704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 529.9897374528828\n",
      "    mean_inference_ms: 2.9958852957853503\n",
      "    mean_raw_obs_processing_ms: 10.473755530980759\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2055122685.2196105\n",
      "    episode_reward_mean: -2084045637.902785\n",
      "    episode_reward_min: -2112968590.5859597\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2112968590.5859597\n",
      "      - -2055122685.2196105\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1655079069591704\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 529.9897374528828\n",
      "      mean_inference_ms: 2.9958852957853503\n",
      "      mean_raw_obs_processing_ms: 10.473755530980759\n",
      "  time_since_restore: 15.094924449920654\n",
      "  time_this_iter_s: 3.5281455516815186\n",
      "  time_total_s: 15.094924449920654\n",
      "  timers:\n",
      "    learn_throughput: 64.194\n",
      "    learn_time_ms: 77.889\n",
      "    load_throughput: 19378.599\n",
      "    load_time_ms: 0.258\n",
      "    training_iteration_time_ms: 3015.489\n",
      "    update_time_ms: 1.815\n",
      "  timestamp: 1656528929\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25\n",
      "  training_iteration: 5\n",
      "  trial_id: e618f_00000\n",
      "  warmup_time: 8.240801334381104\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  5\n",
      "Result for PPOTrainer_compiler_gym_e618f_00001:\n",
      "  agent_timesteps_total: 25\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 25\n",
      "    num_agent_steps_trained: 25\n",
      "    num_env_steps_sampled: 25\n",
      "    num_env_steps_trained: 25\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-29\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2050771745.508801\n",
      "  episode_reward_mean: -2082316364.8820114\n",
      "  episode_reward_min: -2113860984.255222\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 2\n",
      "  experiment_id: 660a5503437348b3848016617fefbbd7\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.012500000186264515\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3854713439941406\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 7.987987191881984e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.00984144862741232\n",
      "          total_loss: 1.9928224086761475\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0026626586914062\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 25\n",
      "    num_agent_steps_trained: 25\n",
      "    num_env_steps_sampled: 25\n",
      "    num_env_steps_trained: 25\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 25\n",
      "  num_agent_steps_trained: 25\n",
      "  num_env_steps_sampled: 25\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 25\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.599999999999994\n",
      "    ram_util_percent: 60.5\n",
      "  pid: 2747508\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1547522359080129\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 548.712877484111\n",
      "    mean_inference_ms: 3.215786182519161\n",
      "    mean_raw_obs_processing_ms: 10.393027619366006\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2050771745.508801\n",
      "    episode_reward_mean: -2082316364.8820114\n",
      "    episode_reward_min: -2113860984.255222\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2113860984.255222\n",
      "      - -2050771745.508801\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1547522359080129\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 548.712877484111\n",
      "      mean_inference_ms: 3.215786182519161\n",
      "      mean_raw_obs_processing_ms: 10.393027619366006\n",
      "  time_since_restore: 15.384925127029419\n",
      "  time_this_iter_s: 3.5220930576324463\n",
      "  time_total_s: 15.384925127029419\n",
      "  timers:\n",
      "    learn_throughput: 70.625\n",
      "    learn_time_ms: 70.796\n",
      "    load_throughput: 24713.08\n",
      "    load_time_ms: 0.202\n",
      "    training_iteration_time_ms: 3073.189\n",
      "    update_time_ms: 1.799\n",
      "  timestamp: 1656528929\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25\n",
      "  training_iteration: 5\n",
      "  trial_id: e618f_00001\n",
      "  warmup_time: 8.27396011352539\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for k_5587 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for n_5625 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  7\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for k_5587 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for n_5625 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  7\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for k_5587 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for n_5625 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  7\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m E0629 14:55:32.054970 139931601782336 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145501-347265-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m E0629 14:55:32.197167 139877103203904 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145435-554058-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  8\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  8\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m E0629 14:55:32.394065 140131922155072 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145448-530599-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  8\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  5\n",
      "Result for PPOTrainer_compiler_gym_e618f_00003:\n",
      "  agent_timesteps_total: 25\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 25\n",
      "    num_agent_steps_trained: 25\n",
      "    num_env_steps_sampled: 25\n",
      "    num_env_steps_trained: 25\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-33\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2025729829.7672005\n",
      "  episode_reward_mean: -2069758653.9125996\n",
      "  episode_reward_min: -2113787478.0579987\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 2\n",
      "  experiment_id: 20a823e5d640460e8655afcd4af39a4b\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.012500000186264515\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3840928077697754\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00023158856492955238\n",
      "          model: {}\n",
      "          policy_loss: -0.016636693850159645\n",
      "          total_loss: 1.9867606163024902\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.003394365310669\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 25\n",
      "    num_agent_steps_trained: 25\n",
      "    num_env_steps_sampled: 25\n",
      "    num_env_steps_trained: 25\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 25\n",
      "  num_agent_steps_trained: 25\n",
      "  num_env_steps_sampled: 25\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 25\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.699999999999996\n",
      "    ram_util_percent: 60.083333333333336\n",
      "  pid: 2748095\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1509426992176931\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 537.1349926118726\n",
      "    mean_inference_ms: 3.2993890506364565\n",
      "    mean_raw_obs_processing_ms: 10.514320233167508\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2025729829.7672005\n",
      "    episode_reward_mean: -2069758653.9125996\n",
      "    episode_reward_min: -2113787478.0579987\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2113787478.0579987\n",
      "      - -2025729829.7672005\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1509426992176931\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 537.1349926118726\n",
      "      mean_inference_ms: 3.2993890506364565\n",
      "      mean_raw_obs_processing_ms: 10.514320233167508\n",
      "  time_since_restore: 15.20829963684082\n",
      "  time_this_iter_s: 3.5267727375030518\n",
      "  time_total_s: 15.20829963684082\n",
      "  timers:\n",
      "    learn_throughput: 69.907\n",
      "    learn_time_ms: 71.523\n",
      "    load_throughput: 21691.684\n",
      "    load_time_ms: 0.231\n",
      "    training_iteration_time_ms: 3037.493\n",
      "    update_time_ms: 1.643\n",
      "  timestamp: 1656528933\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25\n",
      "  training_iteration: 5\n",
      "  trial_id: e618f_00003\n",
      "  warmup_time: 8.29993724822998\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  1\n",
      "Result for PPOTrainer_compiler_gym_e618f_00002:\n",
      "  agent_timesteps_total: 35\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 35\n",
      "    num_agent_steps_trained: 35\n",
      "    num_env_steps_sampled: 35\n",
      "    num_env_steps_trained: 35\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-35\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2062888418.8100266\n",
      "  episode_reward_mean: -2083497903.569709\n",
      "  episode_reward_min: -2116393153.4729571\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 3\n",
      "  experiment_id: 209062bd7460491db9c3ab2ea497b237\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0031250000465661287\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3847308158874512\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.28056433115853e-05\n",
      "          model: {}\n",
      "          policy_loss: 2.38418573772492e-09\n",
      "          total_loss: 2.0000619888305664\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0000619888305664\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 35\n",
      "    num_agent_steps_trained: 35\n",
      "    num_env_steps_sampled: 35\n",
      "    num_env_steps_trained: 35\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 35\n",
      "  num_agent_steps_trained: 35\n",
      "  num_env_steps_sampled: 35\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 35\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.89999999999999\n",
      "    ram_util_percent: 59.35\n",
      "  pid: 2747808\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17327592675093137\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 537.3262134737206\n",
      "    mean_inference_ms: 2.9251380366930135\n",
      "    mean_raw_obs_processing_ms: 10.426326619953393\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2062888418.8100266\n",
      "    episode_reward_mean: -2083497903.569709\n",
      "    episode_reward_min: -2116393153.4729571\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2116393153.4729571\n",
      "      - -2071212138.4261434\n",
      "      - -2062888418.8100266\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17327592675093137\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 537.3262134737206\n",
      "      mean_inference_ms: 2.9251380366930135\n",
      "      mean_raw_obs_processing_ms: 10.426326619953393\n",
      "  time_since_restore: 20.529156923294067\n",
      "  time_this_iter_s: 2.8765950202941895\n",
      "  time_total_s: 20.529156923294067\n",
      "  timers:\n",
      "    learn_throughput: 80.793\n",
      "    learn_time_ms: 61.886\n",
      "    load_throughput: 21232.375\n",
      "    load_time_ms: 0.235\n",
      "    training_iteration_time_ms: 2929.238\n",
      "    update_time_ms: 1.717\n",
      "  timestamp: 1656528935\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35\n",
      "  training_iteration: 7\n",
      "  trial_id: e618f_00002\n",
      "  warmup_time: 8.369242429733276\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:55:35 (running for 00:01:08.45)<br>Memory usage on this node: 18.2/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">      reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>RUNNING </td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         17.6667</td><td style=\"text-align: right;\">  30</td><td style=\"text-align: right;\">-2.07314e+09</td><td style=\"text-align: right;\">        -2.05133e+09</td><td style=\"text-align: right;\">        -2.11297e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>RUNNING </td><td>100.37.253.28:2747508</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         17.9675</td><td style=\"text-align: right;\">  30</td><td style=\"text-align: right;\">-2.06957e+09</td><td style=\"text-align: right;\">        -2.04407e+09</td><td style=\"text-align: right;\">        -2.11386e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>RUNNING </td><td>100.37.253.28:2747808</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         20.5292</td><td style=\"text-align: right;\">  35</td><td style=\"text-align: right;\">-2.0835e+09 </td><td style=\"text-align: right;\">        -2.06289e+09</td><td style=\"text-align: right;\">        -2.11639e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>RUNNING </td><td>100.37.253.28:2748095</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         15.2083</td><td style=\"text-align: right;\">  25</td><td style=\"text-align: right;\">-2.06976e+09</td><td style=\"text-align: right;\">        -2.02573e+09</td><td style=\"text-align: right;\">        -2.11379e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for k_5587 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for n_5625 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  7\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  2\n",
      "Result for PPOTrainer_compiler_gym_e618f_00000:\n",
      "  agent_timesteps_total: 35\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 35\n",
      "    num_agent_steps_trained: 35\n",
      "    num_env_steps_sampled: 35\n",
      "    num_env_steps_trained: 35\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-35\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2051332378.0933416\n",
      "  episode_reward_mean: -2073141217.9663038\n",
      "  episode_reward_min: -2112968590.5859597\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 3\n",
      "  experiment_id: f88dfa7df9ca45168f205a8ba4639621\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0031250000465661287\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3854697942733765\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.7082635167753324e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.0012493033427745104\n",
      "          total_loss: 1.9998844861984253\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.001133680343628\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 35\n",
      "    num_agent_steps_trained: 35\n",
      "    num_env_steps_sampled: 35\n",
      "    num_env_steps_trained: 35\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 35\n",
      "  num_agent_steps_trained: 35\n",
      "  num_env_steps_sampled: 35\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 35\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.22\n",
      "    ram_util_percent: 59.08\n",
      "  pid: 2747313\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16180881767839392\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 533.5695299973275\n",
      "    mean_inference_ms: 2.6834127163080197\n",
      "    mean_raw_obs_processing_ms: 10.571034012441002\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2051332378.0933416\n",
      "    episode_reward_mean: -2073141217.9663038\n",
      "    episode_reward_min: -2112968590.5859597\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2112968590.5859597\n",
      "      - -2055122685.2196105\n",
      "      - -2051332378.0933416\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.16180881767839392\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 533.5695299973275\n",
      "      mean_inference_ms: 2.6834127163080197\n",
      "      mean_raw_obs_processing_ms: 10.571034012441002\n",
      "  time_since_restore: 20.895936727523804\n",
      "  time_this_iter_s: 3.229241371154785\n",
      "  time_total_s: 20.895936727523804\n",
      "  timers:\n",
      "    learn_throughput: 74.876\n",
      "    learn_time_ms: 66.777\n",
      "    load_throughput: 20557.435\n",
      "    load_time_ms: 0.243\n",
      "    training_iteration_time_ms: 2981.481\n",
      "    update_time_ms: 1.724\n",
      "  timestamp: 1656528935\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35\n",
      "  training_iteration: 7\n",
      "  trial_id: e618f_00000\n",
      "  warmup_time: 8.240801334381104\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  2\n",
      "Result for PPOTrainer_compiler_gym_e618f_00001:\n",
      "  agent_timesteps_total: 35\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 35\n",
      "    num_agent_steps_trained: 35\n",
      "    num_env_steps_sampled: 35\n",
      "    num_env_steps_trained: 35\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-35\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2044070528.2569072\n",
      "  episode_reward_mean: -2069567752.6736434\n",
      "  episode_reward_min: -2113860984.255222\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 3\n",
      "  experiment_id: 660a5503437348b3848016617fefbbd7\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0031250000465661287\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3854999542236328\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.4045610441826284e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.0011965993326157331\n",
      "          total_loss: 2.0003628730773926\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.001559257507324\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 35\n",
      "    num_agent_steps_trained: 35\n",
      "    num_env_steps_sampled: 35\n",
      "    num_env_steps_trained: 35\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 35\n",
      "  num_agent_steps_trained: 35\n",
      "  num_env_steps_sampled: 35\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 35\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.08\n",
      "    ram_util_percent: 59.120000000000005\n",
      "  pid: 2747508\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15139536490704725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 549.5443529896921\n",
      "    mean_inference_ms: 2.8481382467568834\n",
      "    mean_raw_obs_processing_ms: 10.523893688553311\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2044070528.2569072\n",
      "    episode_reward_mean: -2069567752.6736434\n",
      "    episode_reward_min: -2113860984.255222\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2113860984.255222\n",
      "      - -2050771745.508801\n",
      "      - -2044070528.2569072\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.15139536490704725\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 549.5443529896921\n",
      "      mean_inference_ms: 2.8481382467568834\n",
      "      mean_raw_obs_processing_ms: 10.523893688553311\n",
      "  time_since_restore: 21.20832324028015\n",
      "  time_this_iter_s: 3.2408394813537598\n",
      "  time_total_s: 21.20832324028015\n",
      "  timers:\n",
      "    learn_throughput: 81.959\n",
      "    learn_time_ms: 61.006\n",
      "    load_throughput: 22955.534\n",
      "    load_time_ms: 0.218\n",
      "    training_iteration_time_ms: 3025.82\n",
      "    update_time_ms: 1.722\n",
      "  timestamp: 1656528935\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35\n",
      "  training_iteration: 7\n",
      "  trial_id: e618f_00001\n",
      "  warmup_time: 8.27396011352539\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  8\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m E0629 14:55:35.827832 139696420152896 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145514-204240-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for n_5625 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m E0629 14:55:38.530462 139931601782336 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145501-347265-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_compiler_gym_e618f_00003:\n",
      "  agent_timesteps_total: 35\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 35\n",
      "    num_agent_steps_trained: 35\n",
      "    num_env_steps_sampled: 35\n",
      "    num_env_steps_trained: 35\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-38\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2025729829.7672005\n",
      "  episode_reward_mean: -2060431414.977375\n",
      "  episode_reward_min: -2113787478.0579987\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 3\n",
      "  experiment_id: 20a823e5d640460e8655afcd4af39a4b\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0031250000465661287\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3841874599456787\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.0799028789042495e-05\n",
      "          model: {}\n",
      "          policy_loss: 2.781550323405213e-09\n",
      "          total_loss: 2.0002291202545166\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0002291202545166\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 35\n",
      "    num_agent_steps_trained: 35\n",
      "    num_env_steps_sampled: 35\n",
      "    num_env_steps_trained: 35\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 35\n",
      "  num_agent_steps_trained: 35\n",
      "  num_env_steps_sampled: 35\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 35\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.9\n",
      "    ram_util_percent: 59.074999999999996\n",
      "  pid: 2748095\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14799941780791015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 540.1482473886673\n",
      "    mean_inference_ms: 2.925636237523179\n",
      "    mean_raw_obs_processing_ms: 10.606696107048721\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2025729829.7672005\n",
      "    episode_reward_mean: -2060431414.977375\n",
      "    episode_reward_min: -2113787478.0579987\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2113787478.0579987\n",
      "      - -2025729829.7672005\n",
      "      - -2041776937.1069262\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14799941780791015\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 540.1482473886673\n",
      "      mean_inference_ms: 2.925636237523179\n",
      "      mean_raw_obs_processing_ms: 10.606696107048721\n",
      "  time_since_restore: 20.724589586257935\n",
      "  time_this_iter_s: 2.9091718196868896\n",
      "  time_total_s: 20.724589586257935\n",
      "  timers:\n",
      "    learn_throughput: 79.83\n",
      "    learn_time_ms: 62.633\n",
      "    load_throughput: 20583.376\n",
      "    load_time_ms: 0.243\n",
      "    training_iteration_time_ms: 2955.474\n",
      "    update_time_ms: 1.59\n",
      "  timestamp: 1656528938\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35\n",
      "  training_iteration: 7\n",
      "  trial_id: e618f_00003\n",
      "  warmup_time: 8.29993724822998\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m E0629 14:55:39.029978 139877103203904 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145435-554058-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m E0629 14:55:39.293113 140131922155072 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145448-530599-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for n_5625 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  2\n",
      "Result for PPOTrainer_compiler_gym_e618f_00002:\n",
      "  agent_timesteps_total: 45\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 45\n",
      "    num_agent_steps_trained: 45\n",
      "    num_env_steps_sampled: 45\n",
      "    num_env_steps_trained: 45\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-41\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2039905120.6167781\n",
      "  episode_reward_mean: -2072599707.8314764\n",
      "  episode_reward_min: -2116393153.4729571\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: 209062bd7460491db9c3ab2ea497b237\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0007812500116415322\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3850891590118408\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00017188582569360733\n",
      "          model: {}\n",
      "          policy_loss: -0.012906868010759354\n",
      "          total_loss: 1.989040493965149\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0019474029541016\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 45\n",
      "    num_agent_steps_trained: 45\n",
      "    num_env_steps_sampled: 45\n",
      "    num_env_steps_trained: 45\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 45\n",
      "  num_agent_steps_trained: 45\n",
      "  num_env_steps_sampled: 45\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 45\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.839999999999996\n",
      "    ram_util_percent: 59.08\n",
      "  pid: 2747808\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1706683712166141\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 543.0883791922864\n",
      "    mean_inference_ms: 2.6644496432833544\n",
      "    mean_raw_obs_processing_ms: 10.518521163561534\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2039905120.6167781\n",
      "    episode_reward_mean: -2072599707.8314764\n",
      "    episode_reward_min: -2116393153.4729571\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2116393153.4729571\n",
      "      - -2071212138.4261434\n",
      "      - -2062888418.8100266\n",
      "      - -2039905120.6167781\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1706683712166141\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 543.0883791922864\n",
      "      mean_inference_ms: 2.6644496432833544\n",
      "      mean_raw_obs_processing_ms: 10.518521163561534\n",
      "  time_since_restore: 27.298911571502686\n",
      "  time_this_iter_s: 3.2439088821411133\n",
      "  time_total_s: 27.298911571502686\n",
      "  timers:\n",
      "    learn_throughput: 89.735\n",
      "    learn_time_ms: 55.719\n",
      "    load_throughput: 20652.553\n",
      "    load_time_ms: 0.242\n",
      "    training_iteration_time_ms: 3029.604\n",
      "    update_time_ms: 1.676\n",
      "  timestamp: 1656528941\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45\n",
      "  training_iteration: 9\n",
      "  trial_id: e618f_00002\n",
      "  warmup_time: 8.369242429733276\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:55:42 (running for 00:01:15.37)<br>Memory usage on this node: 18.2/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">      reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>RUNNING </td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         24.4439</td><td style=\"text-align: right;\">  40</td><td style=\"text-align: right;\">-2.06245e+09</td><td style=\"text-align: right;\">        -2.03039e+09</td><td style=\"text-align: right;\">        -2.11297e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>RUNNING </td><td>100.37.253.28:2747508</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         24.7952</td><td style=\"text-align: right;\">  40</td><td style=\"text-align: right;\">-2.06034e+09</td><td style=\"text-align: right;\">        -2.03266e+09</td><td style=\"text-align: right;\">        -2.11386e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>RUNNING </td><td>100.37.253.28:2747808</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         27.2989</td><td style=\"text-align: right;\">  45</td><td style=\"text-align: right;\">-2.0726e+09 </td><td style=\"text-align: right;\">        -2.03991e+09</td><td style=\"text-align: right;\">        -2.11639e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>RUNNING </td><td>100.37.253.28:2748095</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         20.7246</td><td style=\"text-align: right;\">  35</td><td style=\"text-align: right;\">-2.06043e+09</td><td style=\"text-align: right;\">        -2.02573e+09</td><td style=\"text-align: right;\">        -2.11379e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  4\n",
      "Result for PPOTrainer_compiler_gym_e618f_00000:\n",
      "  agent_timesteps_total: 45\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 45\n",
      "    num_agent_steps_trained: 45\n",
      "    num_env_steps_sampled: 45\n",
      "    num_env_steps_trained: 45\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-42\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2030386789.198473\n",
      "  episode_reward_mean: -2062452610.774346\n",
      "  episode_reward_min: -2112968590.5859597\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: f88dfa7df9ca45168f205a8ba4639621\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0007812500116415322\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3858582973480225\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 6.634005694650114e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.008244151249527931\n",
      "          total_loss: 1.9932926893234253\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0015368461608887\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 45\n",
      "    num_agent_steps_trained: 45\n",
      "    num_env_steps_sampled: 45\n",
      "    num_env_steps_trained: 45\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 45\n",
      "  num_agent_steps_trained: 45\n",
      "  num_env_steps_sampled: 45\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 45\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.52\n",
      "    ram_util_percent: 59.05999999999999\n",
      "  pid: 2747313\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1593320408398382\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 542.3055917974609\n",
      "    mean_inference_ms: 2.476616587331202\n",
      "    mean_raw_obs_processing_ms: 10.638161432204644\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2030386789.198473\n",
      "    episode_reward_mean: -2062452610.774346\n",
      "    episode_reward_min: -2112968590.5859597\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2112968590.5859597\n",
      "      - -2055122685.2196105\n",
      "      - -2051332378.0933416\n",
      "      - -2030386789.198473\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1593320408398382\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 542.3055917974609\n",
      "      mean_inference_ms: 2.476616587331202\n",
      "      mean_raw_obs_processing_ms: 10.638161432204644\n",
      "  time_since_restore: 27.65260624885559\n",
      "  time_this_iter_s: 3.208679676055908\n",
      "  time_total_s: 27.65260624885559\n",
      "  timers:\n",
      "    learn_throughput: 82.809\n",
      "    learn_time_ms: 60.38\n",
      "    load_throughput: 19518.478\n",
      "    load_time_ms: 0.256\n",
      "    training_iteration_time_ms: 3068.903\n",
      "    update_time_ms: 1.74\n",
      "  timestamp: 1656528942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45\n",
      "  training_iteration: 9\n",
      "  trial_id: e618f_00000\n",
      "  warmup_time: 8.240801334381104\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m E0629 14:55:42.422886 139696420152896 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145514-204240-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_compiler_gym_e618f_00001:\n",
      "  agent_timesteps_total: 45\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 45\n",
      "    num_agent_steps_trained: 45\n",
      "    num_env_steps_sampled: 45\n",
      "    num_env_steps_trained: 45\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-42\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2032655828.5176554\n",
      "  episode_reward_mean: -2060339771.6346464\n",
      "  episode_reward_min: -2113860984.255222\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: 660a5503437348b3848016617fefbbd7\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0007812500116415322\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3856467008590698\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.9011938497424126e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.006205678451806307\n",
      "          total_loss: 1.9950404167175293\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.001246213912964\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 45\n",
      "    num_agent_steps_trained: 45\n",
      "    num_env_steps_sampled: 45\n",
      "    num_env_steps_trained: 45\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 45\n",
      "  num_agent_steps_trained: 45\n",
      "  num_env_steps_sampled: 45\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 45\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.5\n",
      "    ram_util_percent: 59.05999999999999\n",
      "  pid: 2747508\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14892260724039166\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 556.676488946728\n",
      "    mean_inference_ms: 2.6042574641672895\n",
      "    mean_raw_obs_processing_ms: 10.610710346694823\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2032655828.5176554\n",
      "    episode_reward_mean: -2060339771.6346464\n",
      "    episode_reward_min: -2113860984.255222\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2113860984.255222\n",
      "      - -2050771745.508801\n",
      "      - -2044070528.2569072\n",
      "      - -2032655828.5176554\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14892260724039166\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 556.676488946728\n",
      "      mean_inference_ms: 2.6042574641672895\n",
      "      mean_raw_obs_processing_ms: 10.610710346694823\n",
      "  time_since_restore: 28.009356021881104\n",
      "  time_this_iter_s: 3.2141878604888916\n",
      "  time_total_s: 28.009356021881104\n",
      "  timers:\n",
      "    learn_throughput: 90.231\n",
      "    learn_time_ms: 55.413\n",
      "    load_throughput: 22900.228\n",
      "    load_time_ms: 0.218\n",
      "    training_iteration_time_ms: 3108.359\n",
      "    update_time_ms: 1.693\n",
      "  timestamp: 1656528942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45\n",
      "  training_iteration: 9\n",
      "  trial_id: e618f_00001\n",
      "  warmup_time: 8.27396011352539\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m cc1: fatal error: /tmp/fn_531.c: No such file or directory\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m compilation terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for m_5586 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for m_5586 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for m_5586 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for k_5587 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for m_5586 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for k_5587 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for m_5586 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for k_5587 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for m_5586 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for k_5587 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for m_5586 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for m_5586 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m E0629 14:55:45.528909 139931601782336 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145501-347265-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747966)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_compiler_gym_e618f_00002:\n",
      "  agent_timesteps_total: 50\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 50\n",
      "    num_agent_steps_trained: 50\n",
      "    num_env_steps_sampled: 50\n",
      "    num_env_steps_trained: 50\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-45\n",
      "  done: true\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2025184045.1230214\n",
      "  episode_reward_mean: -2063116575.2897854\n",
      "  episode_reward_min: -2116393153.4729571\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 5\n",
      "  experiment_id: 209062bd7460491db9c3ab2ea497b237\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0003906250058207661\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3856678009033203\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0001769888331182301\n",
      "          model: {}\n",
      "          policy_loss: -0.010917430743575096\n",
      "          total_loss: 0.843987226486206\n",
      "          vf_explained_var: 0.04394448176026344\n",
      "          vf_loss: 0.8549047112464905\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 50\n",
      "    num_agent_steps_trained: 50\n",
      "    num_env_steps_sampled: 50\n",
      "    num_env_steps_trained: 50\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 50\n",
      "  num_agent_steps_trained: 50\n",
      "  num_env_steps_sampled: 50\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 50\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.260000000000005\n",
      "    ram_util_percent: 59.06\n",
      "  pid: 2747808\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16750760783563426\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 550.9349058980976\n",
      "    mean_inference_ms: 2.478269882305816\n",
      "    mean_raw_obs_processing_ms: 10.588449197323932\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2025184045.1230214\n",
      "    episode_reward_mean: -2063116575.2897854\n",
      "    episode_reward_min: -2116393153.4729571\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2116393153.4729571\n",
      "      - -2071212138.4261434\n",
      "      - -2062888418.8100266\n",
      "      - -2039905120.6167781\n",
      "      - -2025184045.1230214\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.16750760783563426\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 550.9349058980976\n",
      "      mean_inference_ms: 2.478269882305816\n",
      "      mean_raw_obs_processing_ms: 10.588449197323932\n",
      "  time_since_restore: 31.008687019348145\n",
      "  time_this_iter_s: 3.709775447845459\n",
      "  time_total_s: 31.008687019348145\n",
      "  timers:\n",
      "    learn_throughput: 91.092\n",
      "    learn_time_ms: 54.889\n",
      "    load_throughput: 20954.756\n",
      "    load_time_ms: 0.239\n",
      "    training_iteration_time_ms: 3097.234\n",
      "    update_time_ms: 1.617\n",
      "  timestamp: 1656528945\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 50\n",
      "  training_iteration: 10\n",
      "  trial_id: e618f_00002\n",
      "  warmup_time: 8.369242429733276\n",
      "  \n",
      "Result for PPOTrainer_compiler_gym_e618f_00003:\n",
      "  agent_timesteps_total: 45\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 45\n",
      "    num_agent_steps_trained: 45\n",
      "    num_env_steps_sampled: 45\n",
      "    num_env_steps_trained: 45\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-45\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2025729829.7672005\n",
      "  episode_reward_mean: -2058244213.2380633\n",
      "  episode_reward_min: -2113787478.0579987\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: 20a823e5d640460e8655afcd4af39a4b\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0007812500116415322\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3842676877975464\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 9.271511225961149e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.009142829105257988\n",
      "          total_loss: 1.9922738075256348\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0014164447784424\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 45\n",
      "    num_agent_steps_trained: 45\n",
      "    num_env_steps_sampled: 45\n",
      "    num_env_steps_trained: 45\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 45\n",
      "  num_agent_steps_trained: 45\n",
      "  num_env_steps_sampled: 45\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 45\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.900000000000006\n",
      "    ram_util_percent: 59.025\n",
      "  pid: 2748095\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1460645397457478\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 546.7627883214471\n",
      "    mean_inference_ms: 2.676194697111664\n",
      "    mean_raw_obs_processing_ms: 10.672969167923348\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2025729829.7672005\n",
      "    episode_reward_mean: -2058244213.2380633\n",
      "    episode_reward_min: -2113787478.0579987\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2113787478.0579987\n",
      "      - -2025729829.7672005\n",
      "      - -2041776937.1069262\n",
      "      - -2051682608.0201285\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1460645397457478\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 546.7627883214471\n",
      "      mean_inference_ms: 2.676194697111664\n",
      "      mean_raw_obs_processing_ms: 10.672969167923348\n",
      "  time_since_restore: 27.56696128845215\n",
      "  time_this_iter_s: 3.23310923576355\n",
      "  time_total_s: 27.56696128845215\n",
      "  timers:\n",
      "    learn_throughput: 87.778\n",
      "    learn_time_ms: 56.962\n",
      "    load_throughput: 21114.63\n",
      "    load_time_ms: 0.237\n",
      "    training_iteration_time_ms: 3058.203\n",
      "    update_time_ms: 1.595\n",
      "  timestamp: 1656528945\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45\n",
      "  training_iteration: 9\n",
      "  trial_id: e618f_00003\n",
      "  warmup_time: 8.29993724822998\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m E0629 14:55:46.108814 139877103203904 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145435-554058-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m E0629 14:55:46.227114 140131922155072 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145448-530599-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2747668)\u001b[0m \n",
      "Result for PPOTrainer_compiler_gym_e618f_00000:\n",
      "  agent_timesteps_total: 50\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 50\n",
      "    num_agent_steps_trained: 50\n",
      "    num_env_steps_sampled: 50\n",
      "    num_env_steps_trained: 50\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-46\n",
      "  done: true\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2030386789.198473\n",
      "  episode_reward_mean: -2062143252.0039055\n",
      "  episode_reward_min: -2112968590.5859597\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 5\n",
      "  experiment_id: f88dfa7df9ca45168f205a8ba4639621\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0003906250058207661\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3861387968063354\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.2755724280141294e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.005733971484005451\n",
      "          total_loss: 0.9523656368255615\n",
      "          vf_explained_var: 0.07844201475381851\n",
      "          vf_loss: 0.9580997228622437\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 50\n",
      "    num_agent_steps_trained: 50\n",
      "    num_env_steps_sampled: 50\n",
      "    num_env_steps_trained: 50\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 50\n",
      "  num_agent_steps_trained: 50\n",
      "  num_env_steps_sampled: 50\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 50\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.660000000000004\n",
      "    ram_util_percent: 59.08\n",
      "  pid: 2747313\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15685376121430317\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 551.8978171547585\n",
      "    mean_inference_ms: 2.323810075476366\n",
      "    mean_raw_obs_processing_ms: 10.686388522259675\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2030386789.198473\n",
      "    episode_reward_mean: -2062143252.0039055\n",
      "    episode_reward_min: -2112968590.5859597\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2112968590.5859597\n",
      "      - -2055122685.2196105\n",
      "      - -2051332378.0933416\n",
      "      - -2030386789.198473\n",
      "      - -2060905816.9221425\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.15685376121430317\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 551.8978171547585\n",
      "      mean_inference_ms: 2.323810075476366\n",
      "      mean_raw_obs_processing_ms: 10.686388522259675\n",
      "  time_since_restore: 31.4502215385437\n",
      "  time_this_iter_s: 3.7976152896881104\n",
      "  time_total_s: 31.4502215385437\n",
      "  timers:\n",
      "    learn_throughput: 85.778\n",
      "    learn_time_ms: 58.29\n",
      "    load_throughput: 20424.153\n",
      "    load_time_ms: 0.245\n",
      "    training_iteration_time_ms: 3141.37\n",
      "    update_time_ms: 1.712\n",
      "  timestamp: 1656528946\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 50\n",
      "  training_iteration: 10\n",
      "  trial_id: e618f_00000\n",
      "  warmup_time: 8.240801334381104\n",
      "  \n",
      "Result for PPOTrainer_compiler_gym_e618f_00001:\n",
      "  agent_timesteps_total: 50\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 50\n",
      "    num_agent_steps_trained: 50\n",
      "    num_env_steps_sampled: 50\n",
      "    num_env_steps_trained: 50\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-46\n",
      "  done: true\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2032655828.5176554\n",
      "  episode_reward_mean: -2058342156.6313508\n",
      "  episode_reward_min: -2113860984.255222\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 5\n",
      "  experiment_id: 660a5503437348b3848016617fefbbd7\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0003906250058207661\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.385865330696106\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.2798040188499726e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.0021740563679486513\n",
      "          total_loss: 0.3165963888168335\n",
      "          vf_explained_var: 0.012091674841940403\n",
      "          vf_loss: 0.3187703788280487\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 50\n",
      "    num_agent_steps_trained: 50\n",
      "    num_env_steps_sampled: 50\n",
      "    num_env_steps_trained: 50\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 50\n",
      "  num_agent_steps_trained: 50\n",
      "  num_env_steps_sampled: 50\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 50\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.50000000000001\n",
      "    ram_util_percent: 59.1\n",
      "  pid: 2747508\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14809612591754312\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 564.4020525205129\n",
      "    mean_inference_ms: 2.4323563386816986\n",
      "    mean_raw_obs_processing_ms: 10.67363715582888\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2032655828.5176554\n",
      "    episode_reward_mean: -2058342156.6313508\n",
      "    episode_reward_min: -2113860984.255222\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2113860984.255222\n",
      "      - -2050771745.508801\n",
      "      - -2044070528.2569072\n",
      "      - -2032655828.5176554\n",
      "      - -2050351696.6181679\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14809612591754312\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 564.4020525205129\n",
      "      mean_inference_ms: 2.4323563386816986\n",
      "      mean_raw_obs_processing_ms: 10.67363715582888\n",
      "  time_since_restore: 31.663049936294556\n",
      "  time_this_iter_s: 3.653693914413452\n",
      "  time_total_s: 31.663049936294556\n",
      "  timers:\n",
      "    learn_throughput: 94.147\n",
      "    learn_time_ms: 53.108\n",
      "    load_throughput: 23434.484\n",
      "    load_time_ms: 0.213\n",
      "    training_iteration_time_ms: 3162.253\n",
      "    update_time_ms: 1.644\n",
      "  timestamp: 1656528946\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 50\n",
      "  training_iteration: 10\n",
      "  trial_id: e618f_00001\n",
      "  warmup_time: 8.27396011352539\n",
      "  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for m_5586 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for n_5625 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for k_5587 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for m_5586 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for k_5587 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for m_5586 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for m_5586 in 128 : L6  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "Result for PPOTrainer_compiler_gym_e618f_00003:\n",
      "  agent_timesteps_total: 50\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 50\n",
      "    num_agent_steps_trained: 50\n",
      "    num_env_steps_sampled: 50\n",
      "    num_env_steps_trained: 50\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-29_14-55-49\n",
      "  done: true\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2025729829.7672005\n",
      "  episode_reward_mean: -2058932134.9132905\n",
      "  episode_reward_min: -2113787478.0579987\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 5\n",
      "  experiment_id: 20a823e5d640460e8655afcd4af39a4b\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0003906250058207661\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3846781253814697\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.414424256538041e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.004699434619396925\n",
      "          total_loss: 0.27712753415107727\n",
      "          vf_explained_var: 0.0271683931350708\n",
      "          vf_loss: 0.2818268835544586\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 50\n",
      "    num_agent_steps_trained: 50\n",
      "    num_env_steps_sampled: 50\n",
      "    num_env_steps_trained: 50\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 50\n",
      "  num_agent_steps_trained: 50\n",
      "  num_env_steps_sampled: 50\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 50\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.883333333333333\n",
      "    ram_util_percent: 53.93333333333333\n",
      "  pid: 2748095\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14491490101908217\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 555.3297785422297\n",
      "    mean_inference_ms: 2.4980086168273714\n",
      "    mean_raw_obs_processing_ms: 10.719971716330196\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2025729829.7672005\n",
      "    episode_reward_mean: -2058932134.9132905\n",
      "    episode_reward_min: -2113787478.0579987\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2113787478.0579987\n",
      "      - -2025729829.7672005\n",
      "      - -2041776937.1069262\n",
      "      - -2051682608.0201285\n",
      "      - -2061683821.6141994\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14491490101908217\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 555.3297785422297\n",
      "      mean_inference_ms: 2.4980086168273714\n",
      "      mean_raw_obs_processing_ms: 10.719971716330196\n",
      "  time_since_restore: 31.392248392105103\n",
      "  time_this_iter_s: 3.825287103652954\n",
      "  time_total_s: 31.392248392105103\n",
      "  timers:\n",
      "    learn_throughput: 90.875\n",
      "    learn_time_ms: 55.021\n",
      "    load_throughput: 21219.792\n",
      "    load_time_ms: 0.236\n",
      "    training_iteration_time_ms: 3134.547\n",
      "    update_time_ms: 1.612\n",
      "  timestamp: 1656528949\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 50\n",
      "  training_iteration: 10\n",
      "  trial_id: e618f_00003\n",
      "  warmup_time: 8.29993724822998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m E0629 14:55:49.535240 139696420152896 example_service.py:249] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0629T145514-204240-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2748252)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:55:49 (running for 00:01:23.03)<br>Memory usage on this node: 15.8/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">      reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>RUNNING   </td><td>100.37.253.28:2748095</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         31.3922</td><td style=\"text-align: right;\">  50</td><td style=\"text-align: right;\">-2.05893e+09</td><td style=\"text-align: right;\">        -2.02573e+09</td><td style=\"text-align: right;\">        -2.11379e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>TERMINATED</td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         31.4502</td><td style=\"text-align: right;\">  50</td><td style=\"text-align: right;\">-2.06214e+09</td><td style=\"text-align: right;\">        -2.03039e+09</td><td style=\"text-align: right;\">        -2.11297e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>TERMINATED</td><td>100.37.253.28:2747508</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         31.663 </td><td style=\"text-align: right;\">  50</td><td style=\"text-align: right;\">-2.05834e+09</td><td style=\"text-align: right;\">        -2.03266e+09</td><td style=\"text-align: right;\">        -2.11386e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>TERMINATED</td><td>100.37.253.28:2747808</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         31.0087</td><td style=\"text-align: right;\">  50</td><td style=\"text-align: right;\">-2.06312e+09</td><td style=\"text-align: right;\">        -2.02518e+09</td><td style=\"text-align: right;\">        -2.11639e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-29 14:55:49 (running for 00:01:23.19)<br>Memory usage on this node: 15.8/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/10.66 GiB heap, 0.0/5.33 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26<br>Number of trials: 4/4 (4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  model/fcnet_hiddens/0</th><th style=\"text-align: right;\">  model/fcnet_hiddens/1</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">      reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00000</td><td>TERMINATED</td><td>100.37.253.28:2747313</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         31.4502</td><td style=\"text-align: right;\">  50</td><td style=\"text-align: right;\">-2.06214e+09</td><td style=\"text-align: right;\">        -2.03039e+09</td><td style=\"text-align: right;\">        -2.11297e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00001</td><td>TERMINATED</td><td>100.37.253.28:2747508</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         31.663 </td><td style=\"text-align: right;\">  50</td><td style=\"text-align: right;\">-2.05834e+09</td><td style=\"text-align: right;\">        -2.03266e+09</td><td style=\"text-align: right;\">        -2.11386e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00002</td><td>TERMINATED</td><td>100.37.253.28:2747808</td><td style=\"text-align: right;\">                     20</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         31.0087</td><td style=\"text-align: right;\">  50</td><td style=\"text-align: right;\">-2.06312e+09</td><td style=\"text-align: right;\">        -2.02518e+09</td><td style=\"text-align: right;\">        -2.11639e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "<tr><td>PPOTrainer_compiler_gym_e618f_00003</td><td>TERMINATED</td><td>100.37.253.28:2748095</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">                     40</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         31.3922</td><td style=\"text-align: right;\">  50</td><td style=\"text-align: right;\">-2.05893e+09</td><td style=\"text-align: right;\">        -2.02573e+09</td><td style=\"text-align: right;\">        -2.11379e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 14:55:50,536\tINFO tune.py:747 -- Total run time: 83.88 seconds (83.05 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    PPOTrainer,\n",
    "    checkpoint_at_end=True,\n",
    "    stop={\n",
    "        \"episodes_total\": 5,\n",
    "    },\n",
    "    config={\n",
    "        \"seed\": 0xCC,\n",
    "        \"num_workers\": 1,\n",
    "        # Specify the environment to use, where \"compiler_gym\" is the name we \n",
    "        # passed to tune.register_env().\n",
    "        \"env\": \"compiler_gym\",\n",
    "        # Reduce the size of the batch/trajectory lengths to match our short \n",
    "        # training run.\n",
    "        \"rollout_fragment_length\": 5,\n",
    "        \"train_batch_size\": 5,\n",
    "        \"sgd_minibatch_size\": 5,\n",
    "        \"model\": {                            # The NN model we'll optimize.\n",
    "            'fcnet_hiddens': [                # \"Fully-connected network with N hidden layers\".\n",
    "                tune.grid_search([20, 40]),   # Try these four values for layer one.\n",
    "                tune.grid_search([20, 40])    # Try these four values for layer two.\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = analysis.get_best_checkpoint(\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    "    trial=analysis.trials[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>num_agent_steps_sampled</th>\n",
       "      <th>num_agent_steps_trained</th>\n",
       "      <th>num_env_steps_sampled</th>\n",
       "      <th>num_env_steps_trained</th>\n",
       "      <th>...</th>\n",
       "      <th>info/learner/default_policy/learner_stats/entropy</th>\n",
       "      <th>info/learner/default_policy/learner_stats/entropy_coeff</th>\n",
       "      <th>config/env</th>\n",
       "      <th>config/model</th>\n",
       "      <th>config/num_workers</th>\n",
       "      <th>config/rollout_fragment_length</th>\n",
       "      <th>config/seed</th>\n",
       "      <th>config/sgd_minibatch_size</th>\n",
       "      <th>config/train_batch_size</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.030387e+09</td>\n",
       "      <td>-2.112969e+09</td>\n",
       "      <td>-2.062143e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>compiler_gym</td>\n",
       "      <td>{'fcnet_hiddens': [20, 20]}</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>/home/dejang/ray_results/PPOTrainer_2022-06-29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.032656e+09</td>\n",
       "      <td>-2.113861e+09</td>\n",
       "      <td>-2.058342e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.385865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>compiler_gym</td>\n",
       "      <td>{'fcnet_hiddens': [40, 20]}</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>/home/dejang/ray_results/PPOTrainer_2022-06-29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.025184e+09</td>\n",
       "      <td>-2.116393e+09</td>\n",
       "      <td>-2.063117e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.385668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>compiler_gym</td>\n",
       "      <td>{'fcnet_hiddens': [20, 40]}</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>/home/dejang/ray_results/PPOTrainer_2022-06-29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.025730e+09</td>\n",
       "      <td>-2.113787e+09</td>\n",
       "      <td>-2.058932e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>compiler_gym</td>\n",
       "      <td>{'fcnet_hiddens': [40, 40]}</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>/home/dejang/ray_results/PPOTrainer_2022-06-29...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0       -2.030387e+09       -2.112969e+09        -2.062143e+09   \n",
       "1       -2.032656e+09       -2.113861e+09        -2.058342e+09   \n",
       "2       -2.025184e+09       -2.116393e+09        -2.063117e+09   \n",
       "3       -2.025730e+09       -2.113787e+09        -2.058932e+09   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_healthy_workers  \\\n",
       "0              10.0                   1                    1   \n",
       "1              10.0                   1                    1   \n",
       "2              10.0                   1                    1   \n",
       "3              10.0                   1                    1   \n",
       "\n",
       "   num_agent_steps_sampled  num_agent_steps_trained  num_env_steps_sampled  \\\n",
       "0                       50                       50                     50   \n",
       "1                       50                       50                     50   \n",
       "2                       50                       50                     50   \n",
       "3                       50                       50                     50   \n",
       "\n",
       "   num_env_steps_trained  ...  \\\n",
       "0                     50  ...   \n",
       "1                     50  ...   \n",
       "2                     50  ...   \n",
       "3                     50  ...   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/entropy  \\\n",
       "0                                           1.386139   \n",
       "1                                           1.385865   \n",
       "2                                           1.385668   \n",
       "3                                           1.384678   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/entropy_coeff    config/env  \\\n",
       "0                                                0.0        compiler_gym   \n",
       "1                                                0.0        compiler_gym   \n",
       "2                                                0.0        compiler_gym   \n",
       "3                                                0.0        compiler_gym   \n",
       "\n",
       "                  config/model  config/num_workers  \\\n",
       "0  {'fcnet_hiddens': [20, 20]}                   1   \n",
       "1  {'fcnet_hiddens': [40, 20]}                   1   \n",
       "2  {'fcnet_hiddens': [20, 40]}                   1   \n",
       "3  {'fcnet_hiddens': [40, 40]}                   1   \n",
       "\n",
       "   config/rollout_fragment_length  config/seed config/sgd_minibatch_size  \\\n",
       "0                               5          204                         5   \n",
       "1                               5          204                         5   \n",
       "2                               5          204                         5   \n",
       "3                               5          204                         5   \n",
       "\n",
       "  config/train_batch_size                                             logdir  \n",
       "0                       5  /home/dejang/ray_results/PPOTrainer_2022-06-29...  \n",
       "1                       5  /home/dejang/ray_results/PPOTrainer_2022-06-29...  \n",
       "2                       5  /home/dejang/ray_results/PPOTrainer_2022-06-29...  \n",
       "3                       5  /home/dejang/ray_results/PPOTrainer_2022-06-29...  \n",
       "\n",
       "[4 rows x 73 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dejang/ray_results/PPOTrainer_2022-06-29_14-54-26/PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39\n"
     ]
    }
   ],
   "source": [
    "trial = analysis.get_best_trial(metric=\"episode_reward_mean\", mode=\"max\")\n",
    "log_dir = analysis.get_best_logdir(metric=\"episode_reward_mean\", mode=\"max\")\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/global_step</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/agent_timesteps_total</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/counters/num_agent_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/counters/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/counters/num_env_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/counters/num_env_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/done</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episode_len_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episode_reward_max</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episode_reward_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episode_reward_min</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episodes_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episodes_total</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/cur_kl_coeff</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/cur_lr</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/entropy</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/entropy_coeff</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/kl</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/policy_loss</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/total_loss</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/vf_explained_var</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/vf_loss</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/num_agent_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/num_env_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/num_env_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/iterations_since_restore</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_agent_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_env_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_env_steps_sampled_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_env_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_env_steps_trained_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_healthy_workers</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/perf/cpu_util_percent</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/perf/ram_util_percent</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_perf/mean_action_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_perf/mean_env_render_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_perf/mean_env_wait_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_perf/mean_inference_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_perf/mean_raw_obs_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/episode_len_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/episode_reward_max</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/episode_reward_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/episode_reward_min</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/episodes_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/sampler_perf/mean_action_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/sampler_perf/mean_env_render_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/sampler_perf/mean_env_wait_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/sampler_perf/mean_inference_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/sampler_perf/mean_raw_obs_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/time_since_restore</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/time_this_iter_s</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/learn_throughput</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/learn_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/load_throughput</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/load_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/training_iteration_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/update_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timesteps_since_restore</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timesteps_total</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/warmup_time</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/global_step</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/agent_timesteps_total</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/counters/num_agent_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/counters/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/counters/num_env_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/counters/num_env_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/done</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episode_len_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episode_reward_max</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episode_reward_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episode_reward_min</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episodes_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episodes_total</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/cur_kl_coeff</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/cur_lr</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/entropy</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/entropy_coeff</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/kl</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/policy_loss</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/total_loss</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/vf_explained_var</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/vf_loss</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/num_agent_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/num_env_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/num_env_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/iterations_since_restore</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_agent_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_env_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_env_steps_sampled_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_env_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_env_steps_trained_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_healthy_workers</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/perf/cpu_util_percent</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/perf/ram_util_percent</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_perf/mean_action_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_perf/mean_env_render_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_perf/mean_env_wait_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_perf/mean_inference_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_perf/mean_raw_obs_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/episode_len_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/episode_reward_max</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/episode_reward_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/episode_reward_min</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/episodes_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/sampler_perf/mean_action_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/sampler_perf/mean_env_render_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/sampler_perf/mean_env_wait_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/sampler_perf/mean_inference_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/sampler_perf/mean_raw_obs_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/time_since_restore</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/time_this_iter_s</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/learn_throughput</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/learn_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/load_throughput</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/load_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/training_iteration_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/update_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timesteps_since_restore</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timesteps_total</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/warmup_time</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/global_step</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/agent_timesteps_total</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/counters/num_agent_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/counters/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/counters/num_env_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/counters/num_env_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/done</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episode_len_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episode_reward_max</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episode_reward_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episode_reward_min</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episodes_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episodes_total</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/cur_kl_coeff</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/cur_lr</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/entropy</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/entropy_coeff</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/kl</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/policy_loss</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/total_loss</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/vf_explained_var</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/vf_loss</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/num_agent_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/num_env_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/num_env_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/iterations_since_restore</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_agent_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_agent_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_env_steps_sampled</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_env_steps_sampled_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_env_steps_trained</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_env_steps_trained_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_healthy_workers</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/perf/cpu_util_percent</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/perf/ram_util_percent</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_perf/mean_action_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_perf/mean_env_render_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_perf/mean_env_wait_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_perf/mean_inference_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_perf/mean_raw_obs_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/episode_len_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/episode_reward_max</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/episode_reward_mean</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/episode_reward_min</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/episodes_this_iter</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/sampler_perf/mean_action_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/sampler_perf/mean_env_render_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/sampler_perf/mean_env_wait_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/sampler_perf/mean_inference_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/sampler_perf/mean_raw_obs_processing_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/time_since_restore</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/time_this_iter_s</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/learn_throughput</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/learn_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/load_throughput</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/load_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/training_iteration_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/update_time_ms</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timesteps_since_restore</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timesteps_total</td><td></td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/warmup_time</td><td></td></tr><tr><td>global_step</td><td></td></tr><tr><td>ray/tune/agent_timesteps_total</td><td></td></tr><tr><td>ray/tune/counters/num_agent_steps_sampled</td><td></td></tr><tr><td>ray/tune/counters/num_agent_steps_trained</td><td></td></tr><tr><td>ray/tune/counters/num_env_steps_sampled</td><td></td></tr><tr><td>ray/tune/counters/num_env_steps_trained</td><td></td></tr><tr><td>ray/tune/done</td><td></td></tr><tr><td>ray/tune/episode_len_mean</td><td></td></tr><tr><td>ray/tune/episode_reward_max</td><td></td></tr><tr><td>ray/tune/episode_reward_mean</td><td></td></tr><tr><td>ray/tune/episode_reward_min</td><td></td></tr><tr><td>ray/tune/episodes_this_iter</td><td></td></tr><tr><td>ray/tune/episodes_total</td><td></td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/cur_kl_coeff</td><td></td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/cur_lr</td><td></td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/entropy</td><td></td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/entropy_coeff</td><td></td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/kl</td><td></td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/policy_loss</td><td></td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/total_loss</td><td></td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/vf_explained_var</td><td></td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/vf_loss</td><td></td></tr><tr><td>ray/tune/info/learner/default_policy/num_agent_steps_trained</td><td></td></tr><tr><td>ray/tune/info/num_agent_steps_sampled</td><td></td></tr><tr><td>ray/tune/info/num_agent_steps_trained</td><td></td></tr><tr><td>ray/tune/info/num_env_steps_sampled</td><td></td></tr><tr><td>ray/tune/info/num_env_steps_trained</td><td></td></tr><tr><td>ray/tune/iterations_since_restore</td><td></td></tr><tr><td>ray/tune/num_agent_steps_sampled</td><td></td></tr><tr><td>ray/tune/num_agent_steps_trained</td><td></td></tr><tr><td>ray/tune/num_env_steps_sampled</td><td></td></tr><tr><td>ray/tune/num_env_steps_sampled_this_iter</td><td></td></tr><tr><td>ray/tune/num_env_steps_trained</td><td></td></tr><tr><td>ray/tune/num_env_steps_trained_this_iter</td><td></td></tr><tr><td>ray/tune/num_healthy_workers</td><td></td></tr><tr><td>ray/tune/perf/cpu_util_percent</td><td></td></tr><tr><td>ray/tune/perf/ram_util_percent</td><td></td></tr><tr><td>ray/tune/sampler_perf/mean_action_processing_ms</td><td></td></tr><tr><td>ray/tune/sampler_perf/mean_env_render_ms</td><td></td></tr><tr><td>ray/tune/sampler_perf/mean_env_wait_ms</td><td></td></tr><tr><td>ray/tune/sampler_perf/mean_inference_ms</td><td></td></tr><tr><td>ray/tune/sampler_perf/mean_raw_obs_processing_ms</td><td></td></tr><tr><td>ray/tune/sampler_results/episode_len_mean</td><td></td></tr><tr><td>ray/tune/sampler_results/episode_reward_max</td><td></td></tr><tr><td>ray/tune/sampler_results/episode_reward_mean</td><td></td></tr><tr><td>ray/tune/sampler_results/episode_reward_min</td><td></td></tr><tr><td>ray/tune/sampler_results/episodes_this_iter</td><td></td></tr><tr><td>ray/tune/sampler_results/sampler_perf/mean_action_processing_ms</td><td></td></tr><tr><td>ray/tune/sampler_results/sampler_perf/mean_env_render_ms</td><td></td></tr><tr><td>ray/tune/sampler_results/sampler_perf/mean_env_wait_ms</td><td></td></tr><tr><td>ray/tune/sampler_results/sampler_perf/mean_inference_ms</td><td></td></tr><tr><td>ray/tune/sampler_results/sampler_perf/mean_raw_obs_processing_ms</td><td></td></tr><tr><td>ray/tune/time_since_restore</td><td></td></tr><tr><td>ray/tune/time_this_iter_s</td><td></td></tr><tr><td>ray/tune/timers/learn_throughput</td><td></td></tr><tr><td>ray/tune/timers/learn_time_ms</td><td></td></tr><tr><td>ray/tune/timers/load_throughput</td><td></td></tr><tr><td>ray/tune/timers/load_time_ms</td><td></td></tr><tr><td>ray/tune/timers/training_iteration_time_ms</td><td></td></tr><tr><td>ray/tune/timers/update_time_ms</td><td></td></tr><tr><td>ray/tune/timesteps_since_restore</td><td></td></tr><tr><td>ray/tune/timesteps_total</td><td></td></tr><tr><td>ray/tune/warmup_time</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/global_step</td><td>0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/agent_timesteps_total</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/counters/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/counters/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/counters/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/counters/num_env_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/done</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episode_len_mean</td><td>10.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episode_reward_max</td><td>-2032655872.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episode_reward_mean</td><td>-2058342144.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episode_reward_min</td><td>-2113860992.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episodes_this_iter</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/episodes_total</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/cur_kl_coeff</td><td>0.00039</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/cur_lr</td><td>5e-05</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/entropy</td><td>1.38587</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/entropy_coeff</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/kl</td><td>1e-05</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/policy_loss</td><td>-0.00217</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/total_loss</td><td>0.3166</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/vf_explained_var</td><td>0.01209</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/learner_stats/vf_loss</td><td>0.31877</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/learner/default_policy/num_agent_steps_trained</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/info/num_env_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/iterations_since_restore</td><td>10.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_env_steps_sampled_this_iter</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_env_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_env_steps_trained_this_iter</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/num_healthy_workers</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/perf/cpu_util_percent</td><td>37.5</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/perf/ram_util_percent</td><td>59.1</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_perf/mean_action_processing_ms</td><td>0.1481</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_perf/mean_env_render_ms</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_perf/mean_env_wait_ms</td><td>564.40204</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_perf/mean_inference_ms</td><td>2.43236</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_perf/mean_raw_obs_processing_ms</td><td>10.67364</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/episode_len_mean</td><td>10.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/episode_reward_max</td><td>-2032655872.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/episode_reward_mean</td><td>-2058342144.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/episode_reward_min</td><td>-2113860992.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/episodes_this_iter</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/sampler_perf/mean_action_processing_ms</td><td>0.1481</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/sampler_perf/mean_env_render_ms</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/sampler_perf/mean_env_wait_ms</td><td>564.40204</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/sampler_perf/mean_inference_ms</td><td>2.43236</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/sampler_results/sampler_perf/mean_raw_obs_processing_ms</td><td>10.67364</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/time_since_restore</td><td>31.66305</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/time_this_iter_s</td><td>3.65369</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/learn_throughput</td><td>94.147</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/learn_time_ms</td><td>53.108</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/load_throughput</td><td>23434.48438</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/load_time_ms</td><td>0.213</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/training_iteration_time_ms</td><td>3162.25293</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timers/update_time_ms</td><td>1.644</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timesteps_since_restore</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/timesteps_total</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00001_1_0=40,1=20_2022-06-29_14-54-39/ray/tune/warmup_time</td><td>8.27396</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/global_step</td><td>0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/agent_timesteps_total</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/counters/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/counters/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/counters/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/counters/num_env_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/done</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episode_len_mean</td><td>10.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episode_reward_max</td><td>-2025184000.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episode_reward_mean</td><td>-2063116544.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episode_reward_min</td><td>-2116393216.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episodes_this_iter</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/episodes_total</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/cur_kl_coeff</td><td>0.00039</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/cur_lr</td><td>5e-05</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/entropy</td><td>1.38567</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/entropy_coeff</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/kl</td><td>0.00018</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/policy_loss</td><td>-0.01092</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/total_loss</td><td>0.84399</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/vf_explained_var</td><td>0.04394</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/learner_stats/vf_loss</td><td>0.8549</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/learner/default_policy/num_agent_steps_trained</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/info/num_env_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/iterations_since_restore</td><td>10.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_env_steps_sampled_this_iter</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_env_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_env_steps_trained_this_iter</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/num_healthy_workers</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/perf/cpu_util_percent</td><td>39.26</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/perf/ram_util_percent</td><td>59.06</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_perf/mean_action_processing_ms</td><td>0.16751</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_perf/mean_env_render_ms</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_perf/mean_env_wait_ms</td><td>550.93488</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_perf/mean_inference_ms</td><td>2.47827</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_perf/mean_raw_obs_processing_ms</td><td>10.58845</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/episode_len_mean</td><td>10.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/episode_reward_max</td><td>-2025184000.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/episode_reward_mean</td><td>-2063116544.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/episode_reward_min</td><td>-2116393216.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/episodes_this_iter</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/sampler_perf/mean_action_processing_ms</td><td>0.16751</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/sampler_perf/mean_env_render_ms</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/sampler_perf/mean_env_wait_ms</td><td>550.93488</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/sampler_perf/mean_inference_ms</td><td>2.47827</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/sampler_results/sampler_perf/mean_raw_obs_processing_ms</td><td>10.58845</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/time_since_restore</td><td>31.00869</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/time_this_iter_s</td><td>3.70978</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/learn_throughput</td><td>91.092</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/learn_time_ms</td><td>54.889</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/load_throughput</td><td>20954.75586</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/load_time_ms</td><td>0.239</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/training_iteration_time_ms</td><td>3097.23389</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timers/update_time_ms</td><td>1.617</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timesteps_since_restore</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/timesteps_total</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00002_2_0=20,1=40_2022-06-29_14-54-52/ray/tune/warmup_time</td><td>8.36924</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/global_step</td><td>0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/agent_timesteps_total</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/counters/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/counters/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/counters/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/counters/num_env_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/done</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episode_len_mean</td><td>10.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episode_reward_max</td><td>-2025729792.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episode_reward_mean</td><td>-2058932096.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episode_reward_min</td><td>-2113787520.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episodes_this_iter</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/episodes_total</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/cur_kl_coeff</td><td>0.00039</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/cur_lr</td><td>5e-05</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/entropy</td><td>1.38468</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/entropy_coeff</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/kl</td><td>4e-05</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/policy_loss</td><td>-0.0047</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/total_loss</td><td>0.27713</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/vf_explained_var</td><td>0.02717</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/learner_stats/vf_loss</td><td>0.28183</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/learner/default_policy/num_agent_steps_trained</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/info/num_env_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/iterations_since_restore</td><td>10.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_env_steps_sampled_this_iter</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_env_steps_trained</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_env_steps_trained_this_iter</td><td>5.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/num_healthy_workers</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/perf/cpu_util_percent</td><td>20.88333</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/perf/ram_util_percent</td><td>53.93333</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_perf/mean_action_processing_ms</td><td>0.14491</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_perf/mean_env_render_ms</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_perf/mean_env_wait_ms</td><td>555.32977</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_perf/mean_inference_ms</td><td>2.49801</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_perf/mean_raw_obs_processing_ms</td><td>10.71997</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/episode_len_mean</td><td>10.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/episode_reward_max</td><td>-2025729792.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/episode_reward_mean</td><td>-2058932096.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/episode_reward_min</td><td>-2113787520.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/episodes_this_iter</td><td>1.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/sampler_perf/mean_action_processing_ms</td><td>0.14491</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/sampler_perf/mean_env_render_ms</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/sampler_perf/mean_env_wait_ms</td><td>555.32977</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/sampler_perf/mean_inference_ms</td><td>2.49801</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/sampler_results/sampler_perf/mean_raw_obs_processing_ms</td><td>10.71997</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/time_since_restore</td><td>31.39225</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/time_this_iter_s</td><td>3.82529</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/learn_throughput</td><td>90.875</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/learn_time_ms</td><td>55.021</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/load_throughput</td><td>21219.79297</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/load_time_ms</td><td>0.236</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/training_iteration_time_ms</td><td>3134.54712</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timers/update_time_ms</td><td>1.612</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timesteps_since_restore</td><td>0.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/timesteps_total</td><td>50.0</td></tr><tr><td>PPOTrainer_compiler_gym_e618f_00003_3_0=40,1=40_2022-06-29_14-55-05/ray/tune/warmup_time</td><td>8.29994</td></tr><tr><td>global_step</td><td>50</td></tr><tr><td>ray/tune/agent_timesteps_total</td><td>50.0</td></tr><tr><td>ray/tune/counters/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>ray/tune/counters/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>ray/tune/counters/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>ray/tune/counters/num_env_steps_trained</td><td>50.0</td></tr><tr><td>ray/tune/done</td><td>1.0</td></tr><tr><td>ray/tune/episode_len_mean</td><td>10.0</td></tr><tr><td>ray/tune/episode_reward_max</td><td>-2030386816.0</td></tr><tr><td>ray/tune/episode_reward_mean</td><td>-2062143232.0</td></tr><tr><td>ray/tune/episode_reward_min</td><td>-2112968576.0</td></tr><tr><td>ray/tune/episodes_this_iter</td><td>1.0</td></tr><tr><td>ray/tune/episodes_total</td><td>5.0</td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/cur_kl_coeff</td><td>0.00039</td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/cur_lr</td><td>5e-05</td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/entropy</td><td>1.38614</td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/entropy_coeff</td><td>0.0</td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/kl</td><td>4e-05</td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/policy_loss</td><td>-0.00573</td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/total_loss</td><td>0.95237</td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/vf_explained_var</td><td>0.07844</td></tr><tr><td>ray/tune/info/learner/default_policy/learner_stats/vf_loss</td><td>0.9581</td></tr><tr><td>ray/tune/info/learner/default_policy/num_agent_steps_trained</td><td>5.0</td></tr><tr><td>ray/tune/info/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>ray/tune/info/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>ray/tune/info/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>ray/tune/info/num_env_steps_trained</td><td>50.0</td></tr><tr><td>ray/tune/iterations_since_restore</td><td>10.0</td></tr><tr><td>ray/tune/num_agent_steps_sampled</td><td>50.0</td></tr><tr><td>ray/tune/num_agent_steps_trained</td><td>50.0</td></tr><tr><td>ray/tune/num_env_steps_sampled</td><td>50.0</td></tr><tr><td>ray/tune/num_env_steps_sampled_this_iter</td><td>5.0</td></tr><tr><td>ray/tune/num_env_steps_trained</td><td>50.0</td></tr><tr><td>ray/tune/num_env_steps_trained_this_iter</td><td>5.0</td></tr><tr><td>ray/tune/num_healthy_workers</td><td>1.0</td></tr><tr><td>ray/tune/perf/cpu_util_percent</td><td>38.66</td></tr><tr><td>ray/tune/perf/ram_util_percent</td><td>59.08</td></tr><tr><td>ray/tune/sampler_perf/mean_action_processing_ms</td><td>0.15685</td></tr><tr><td>ray/tune/sampler_perf/mean_env_render_ms</td><td>0.0</td></tr><tr><td>ray/tune/sampler_perf/mean_env_wait_ms</td><td>551.89783</td></tr><tr><td>ray/tune/sampler_perf/mean_inference_ms</td><td>2.32381</td></tr><tr><td>ray/tune/sampler_perf/mean_raw_obs_processing_ms</td><td>10.68639</td></tr><tr><td>ray/tune/sampler_results/episode_len_mean</td><td>10.0</td></tr><tr><td>ray/tune/sampler_results/episode_reward_max</td><td>-2030386816.0</td></tr><tr><td>ray/tune/sampler_results/episode_reward_mean</td><td>-2062143232.0</td></tr><tr><td>ray/tune/sampler_results/episode_reward_min</td><td>-2112968576.0</td></tr><tr><td>ray/tune/sampler_results/episodes_this_iter</td><td>1.0</td></tr><tr><td>ray/tune/sampler_results/sampler_perf/mean_action_processing_ms</td><td>0.15685</td></tr><tr><td>ray/tune/sampler_results/sampler_perf/mean_env_render_ms</td><td>0.0</td></tr><tr><td>ray/tune/sampler_results/sampler_perf/mean_env_wait_ms</td><td>551.89783</td></tr><tr><td>ray/tune/sampler_results/sampler_perf/mean_inference_ms</td><td>2.32381</td></tr><tr><td>ray/tune/sampler_results/sampler_perf/mean_raw_obs_processing_ms</td><td>10.68639</td></tr><tr><td>ray/tune/time_since_restore</td><td>31.45022</td></tr><tr><td>ray/tune/time_this_iter_s</td><td>3.79762</td></tr><tr><td>ray/tune/timers/learn_throughput</td><td>85.778</td></tr><tr><td>ray/tune/timers/learn_time_ms</td><td>58.29</td></tr><tr><td>ray/tune/timers/load_throughput</td><td>20424.15234</td></tr><tr><td>ray/tune/timers/load_time_ms</td><td>0.245</td></tr><tr><td>ray/tune/timers/training_iteration_time_ms</td><td>3141.37012</td></tr><tr><td>ray/tune/timers/update_time_ms</td><td>1.712</td></tr><tr><td>ray/tune/timesteps_since_restore</td><td>0.0</td></tr><tr><td>ray/tune/timesteps_total</td><td>50.0</td></tr><tr><td>ray/tune/warmup_time</td><td>8.2408</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rural-disco-5</strong>: <a href=\"https://wandb.ai/dejang/loop_tool/runs/2wnj7kv5\" target=\"_blank\">https://wandb.ai/dejang/loop_tool/runs/2wnj7kv5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 4 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220629_145412-2wnj7kv5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# wandb.tensorboard.patch(root_logdir=log_dir, save=False, tensorboard_x=True)\n",
    "# If running in a notebook, finish the wandb run to upload the tensorboard logs to W&B\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episodes_total': 5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.stopping_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_reward_max': {'max': -2032655828.5176554,\n",
       "  'min': -2113860984.255222,\n",
       "  'avg': nan,\n",
       "  'last': -2032655828.5176554,\n",
       "  'last-5-avg': -2037221708.413356,\n",
       "  'last-10-avg': nan},\n",
       " 'episode_reward_min': {'max': -2113860984.255222,\n",
       "  'min': -2113860984.255222,\n",
       "  'avg': nan,\n",
       "  'last': -2113860984.255222,\n",
       "  'last-5-avg': -2113860984.2552218,\n",
       "  'last-10-avg': nan},\n",
       " 'episode_reward_mean': {'max': -2058342156.6313508,\n",
       "  'min': -2113860984.255222,\n",
       "  'avg': nan,\n",
       "  'last': -2058342156.6313508,\n",
       "  'last-5-avg': -2063631441.049586,\n",
       "  'last-10-avg': nan},\n",
       " 'episode_len_mean': {'max': 10.0,\n",
       "  'min': 10.0,\n",
       "  'avg': nan,\n",
       "  'last': 10.0,\n",
       "  'last-5-avg': 10.0,\n",
       "  'last-10-avg': nan},\n",
       " 'episodes_this_iter': {'max': 1,\n",
       "  'min': 0,\n",
       "  'avg': 0.5,\n",
       "  'last': 1,\n",
       "  'last-5-avg': 0.6,\n",
       "  'last-10-avg': 0.5},\n",
       " 'num_healthy_workers': {'max': 1,\n",
       "  'min': 1,\n",
       "  'avg': 1.0,\n",
       "  'last': 1,\n",
       "  'last-5-avg': 1.0,\n",
       "  'last-10-avg': 1.0},\n",
       " 'num_agent_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'num_agent_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'num_env_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'num_env_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'num_env_steps_sampled_this_iter': {'max': 5,\n",
       "  'min': 5,\n",
       "  'avg': 5.0,\n",
       "  'last': 5,\n",
       "  'last-5-avg': 5.0,\n",
       "  'last-10-avg': 5.0},\n",
       " 'num_env_steps_trained_this_iter': {'max': 5,\n",
       "  'min': 5,\n",
       "  'avg': 5.0,\n",
       "  'last': 5,\n",
       "  'last-5-avg': 5.0,\n",
       "  'last-10-avg': 5.0},\n",
       " 'timesteps_total': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'agent_timesteps_total': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'done': {'max': True,\n",
       "  'min': False,\n",
       "  'avg': 0.1,\n",
       "  'last': True,\n",
       "  'last-5-avg': 0.2,\n",
       "  'last-10-avg': 0.1},\n",
       " 'episodes_total': {'max': 5,\n",
       "  'min': 0,\n",
       "  'avg': 2.5,\n",
       "  'last': 5,\n",
       "  'last-5-avg': 3.8,\n",
       "  'last-10-avg': 2.5},\n",
       " 'training_iteration': {'max': 10,\n",
       "  'min': 1,\n",
       "  'avg': 5.5,\n",
       "  'last': 10,\n",
       "  'last-5-avg': 8.0,\n",
       "  'last-10-avg': 5.5},\n",
       " 'time_this_iter_s': {'max': 3.653693914413452,\n",
       "  'min': 2.472761869430542,\n",
       "  'avg': 3.1663049936294554,\n",
       "  'last': 3.653693914413452,\n",
       "  'last-5-avg': 3.2556249618530275,\n",
       "  'last-10-avg': 3.1663049936294554},\n",
       " 'time_total_s': {'max': 31.663049936294556,\n",
       "  'min': 3.5679571628570557,\n",
       "  'avg': 17.05071063041687,\n",
       "  'last': 31.663049936294556,\n",
       "  'last-5-avg': 24.72867622375488,\n",
       "  'last-10-avg': 17.05071063041687},\n",
       " 'time_since_restore': {'max': 31.663049936294556,\n",
       "  'min': 3.5679571628570557,\n",
       "  'avg': 17.05071063041687,\n",
       "  'last': 31.663049936294556,\n",
       "  'last-5-avg': 24.72867622375488,\n",
       "  'last-10-avg': 17.05071063041687},\n",
       " 'timesteps_since_restore': {'max': 0,\n",
       "  'min': 0,\n",
       "  'avg': 0.0,\n",
       "  'last': 0,\n",
       "  'last-5-avg': 0.0,\n",
       "  'last-10-avg': 0.0},\n",
       " 'iterations_since_restore': {'max': 10,\n",
       "  'min': 1,\n",
       "  'avg': 5.5,\n",
       "  'last': 10,\n",
       "  'last-5-avg': 8.0,\n",
       "  'last-10-avg': 5.5},\n",
       " 'warmup_time': {'max': 8.27396011352539,\n",
       "  'min': 8.27396011352539,\n",
       "  'avg': 8.27396011352539,\n",
       "  'last': 8.27396011352539,\n",
       "  'last-5-avg': 8.27396011352539,\n",
       "  'last-10-avg': 8.27396011352539},\n",
       " 'info/num_env_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'info/num_env_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'info/num_agent_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'info/num_agent_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'sampler_results/episode_reward_max': {'max': -2032655828.5176554,\n",
       "  'min': -2113860984.255222,\n",
       "  'avg': nan,\n",
       "  'last': -2032655828.5176554,\n",
       "  'last-5-avg': -2037221708.413356,\n",
       "  'last-10-avg': nan},\n",
       " 'sampler_results/episode_reward_min': {'max': -2113860984.255222,\n",
       "  'min': -2113860984.255222,\n",
       "  'avg': nan,\n",
       "  'last': -2113860984.255222,\n",
       "  'last-5-avg': -2113860984.2552218,\n",
       "  'last-10-avg': nan},\n",
       " 'sampler_results/episode_reward_mean': {'max': -2058342156.6313508,\n",
       "  'min': -2113860984.255222,\n",
       "  'avg': nan,\n",
       "  'last': -2058342156.6313508,\n",
       "  'last-5-avg': -2063631441.049586,\n",
       "  'last-10-avg': nan},\n",
       " 'sampler_results/episode_len_mean': {'max': 10.0,\n",
       "  'min': 10.0,\n",
       "  'avg': nan,\n",
       "  'last': 10.0,\n",
       "  'last-5-avg': 10.0,\n",
       "  'last-10-avg': nan},\n",
       " 'sampler_results/episodes_this_iter': {'max': 1,\n",
       "  'min': 0,\n",
       "  'avg': 0.5,\n",
       "  'last': 1,\n",
       "  'last-5-avg': 0.6,\n",
       "  'last-10-avg': 0.5},\n",
       " 'timers/training_iteration_time_ms': {'max': 3565.591,\n",
       "  'min': 2961.729,\n",
       "  'avg': 3143.4675,\n",
       "  'last': 3162.253,\n",
       "  'last-5-avg': 3076.5516000000002,\n",
       "  'last-10-avg': 3143.4674999999997},\n",
       " 'timers/load_time_ms': {'max': 0.228,\n",
       "  'min': 0.15,\n",
       "  'avg': 0.1975,\n",
       "  'last': 0.213,\n",
       "  'last-5-avg': 0.2186,\n",
       "  'last-10-avg': 0.19749999999999998},\n",
       " 'timers/load_throughput': {'max': 33288.127,\n",
       "  'min': 21968.333,\n",
       "  'avg': 25827.90599999999,\n",
       "  'last': 23434.484,\n",
       "  'last-5-avg': 22880.339,\n",
       "  'last-10-avg': 25827.906},\n",
       " 'timers/learn_time_ms': {'max': 205.512,\n",
       "  'min': 53.108,\n",
       "  'avg': 86.93979999999999,\n",
       "  'last': 53.108,\n",
       "  'last-5-avg': 58.682,\n",
       "  'last-10-avg': 86.9398},\n",
       " 'timers/learn_throughput': {'max': 94.147,\n",
       "  'min': 24.329,\n",
       "  'avg': 67.86710000000001,\n",
       "  'last': 94.147,\n",
       "  'last-5-avg': 85.67679999999999,\n",
       "  'last-10-avg': 67.86710000000001},\n",
       " 'timers/update_time_ms': {'max': 2.364,\n",
       "  'min': 1.644,\n",
       "  'avg': 1.8544999999999998,\n",
       "  'last': 1.644,\n",
       "  'last-5-avg': 1.7138000000000002,\n",
       "  'last-10-avg': 1.8545000000000003},\n",
       " 'counters/num_env_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'counters/num_env_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'counters/num_agent_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'counters/num_agent_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'perf/cpu_util_percent': {'max': 42.266666666666666,\n",
       "  'min': 19.794444444444444,\n",
       "  'avg': 37.56911111111111,\n",
       "  'last': 37.50000000000001,\n",
       "  'last-5-avg': 39.361000000000004,\n",
       "  'last-10-avg': 37.56911111111111},\n",
       " 'perf/ram_util_percent': {'max': 60.55,\n",
       "  'min': 55.400000000000006,\n",
       "  'avg': 59.253277777777775,\n",
       "  'last': 59.1,\n",
       "  'last-5-avg': 59.386,\n",
       "  'last-10-avg': 59.25327777777778},\n",
       " 'info/learner/default_policy/num_agent_steps_trained': {'max': 5.0,\n",
       "  'min': 5.0,\n",
       "  'avg': 5.0,\n",
       "  'last': 5.0,\n",
       "  'last-5-avg': 5.0,\n",
       "  'last-10-avg': 5.0},\n",
       " 'info/learner/default_policy/learner_stats/cur_kl_coeff': {'max': 0.20000000298023224,\n",
       "  'min': 0.0003906250058207661,\n",
       "  'avg': 0.039960938095464374,\n",
       "  'last': 0.0003906250058207661,\n",
       "  'last-5-avg': 0.0024218750360887496,\n",
       "  'last-10-avg': 0.039960938095464374},\n",
       " 'info/learner/default_policy/learner_stats/cur_lr': {'max': 4.999999873689376e-05,\n",
       "  'min': 4.999999873689376e-05,\n",
       "  'avg': 4.999999873689376e-05,\n",
       "  'last': 4.999999873689376e-05,\n",
       "  'last-5-avg': 4.999999873689376e-05,\n",
       "  'last-10-avg': 4.999999873689376e-05},\n",
       " 'info/learner/default_policy/learner_stats/total_loss': {'max': 9.998767,\n",
       "  'min': 0.0023595726,\n",
       "  'avg': 4.077292615524493,\n",
       "  'last': 0.3165964,\n",
       "  'last-5-avg': 2.862625230057165,\n",
       "  'last-10-avg': 4.0772926155244935},\n",
       " 'info/learner/default_policy/learner_stats/policy_loss': {'max': -0.0011804501,\n",
       "  'min': -0.009841449,\n",
       "  'avg': -0.0039804765256121755,\n",
       "  'last': -0.0021740564,\n",
       "  'last-5-avg': -0.0023978480603545904,\n",
       "  'last-10-avg': -0.0039804765256121755},\n",
       " 'info/learner/default_policy/learner_stats/vf_loss': {'max': 10.0,\n",
       "  'min': 0.0035400162,\n",
       "  'avg': 4.081271619303152,\n",
       "  'last': 0.31877038,\n",
       "  'last-5-avg': 2.865023173298687,\n",
       "  'last-10-avg': 4.081271619303152},\n",
       " 'info/learner/default_policy/learner_stats/vf_explained_var': {'max': 0.012091675,\n",
       "  'min': -1.1920929e-08,\n",
       "  'avg': 0.002008469514548761,\n",
       "  'last': 0.012091675,\n",
       "  'last-5-avg': 0.003218520525842905,\n",
       "  'last-10-avg': 0.002008469514548761},\n",
       " 'info/learner/default_policy/learner_stats/kl': {'max': 7.987987e-05,\n",
       "  'min': 7.3671345e-06,\n",
       "  'avg': 2.887321879825322e-05,\n",
       "  'last': 1.279804e-05,\n",
       "  'last-5-avg': 1.646589571464574e-05,\n",
       "  'last-10-avg': 2.887321879825322e-05},\n",
       " 'info/learner/default_policy/learner_stats/entropy': {'max': 1.3862145,\n",
       "  'min': 1.3854713,\n",
       "  'avg': 1.3858063459396364,\n",
       "  'last': 1.3858653,\n",
       "  'last-5-avg': 1.3856436014175415,\n",
       "  'last-10-avg': 1.3858063459396361},\n",
       " 'info/learner/default_policy/learner_stats/entropy_coeff': {'max': 0.0,\n",
       "  'min': 0.0,\n",
       "  'avg': 0.0,\n",
       "  'last': 0.0,\n",
       "  'last-5-avg': 0.0,\n",
       "  'last-10-avg': 0.0},\n",
       " 'sampler_perf/mean_raw_obs_processing_ms': {'max': 10.67363715582888,\n",
       "  'min': 10.189359838312322,\n",
       "  'avg': 10.429697997999416,\n",
       "  'last': 10.67363715582888,\n",
       "  'last-5-avg': 10.588569045265029,\n",
       "  'last-10-avg': 10.456402237964646},\n",
       " 'sampler_perf/mean_inference_ms': {'max': 3.8465586575594815,\n",
       "  'min': 2.4323563386816986,\n",
       "  'avg': 3.1308396098246805,\n",
       "  'last': 2.4323563386816986,\n",
       "  'last-5-avg': 2.6674295521060087,\n",
       "  'last-10-avg': 3.051315271187481},\n",
       " 'sampler_perf/mean_action_processing_ms': {'max': 0.15824491327459161,\n",
       "  'min': 0.14809612591754312,\n",
       "  'avg': 0.15329712818522218,\n",
       "  'last': 0.14809612591754312,\n",
       "  'last-5-avg': 0.14974641404248418,\n",
       "  'last-10-avg': 0.15274737428640334},\n",
       " 'sampler_perf/mean_env_wait_ms': {'max': 564.4020525205129,\n",
       "  'min': 548.712877484111,\n",
       "  'avg': 556.6603254657529,\n",
       "  'last': 564.4020525205129,\n",
       "  'last-5-avg': 555.3687472786706,\n",
       "  'last-10-avg': 555.8324444695049},\n",
       " 'sampler_perf/mean_env_render_ms': {'max': 0.0,\n",
       "  'min': 0.0,\n",
       "  'avg': 0.0,\n",
       "  'last': 0.0,\n",
       "  'last-5-avg': 0.0,\n",
       "  'last-10-avg': 0.0},\n",
       " 'sampler_results/sampler_perf/mean_raw_obs_processing_ms': {'max': 10.67363715582888,\n",
       "  'min': 10.189359838312322,\n",
       "  'avg': 10.429697997999416,\n",
       "  'last': 10.67363715582888,\n",
       "  'last-5-avg': 10.588569045265029,\n",
       "  'last-10-avg': 10.456402237964646},\n",
       " 'sampler_results/sampler_perf/mean_inference_ms': {'max': 3.8465586575594815,\n",
       "  'min': 2.4323563386816986,\n",
       "  'avg': 3.1308396098246805,\n",
       "  'last': 2.4323563386816986,\n",
       "  'last-5-avg': 2.6674295521060087,\n",
       "  'last-10-avg': 3.051315271187481},\n",
       " 'sampler_results/sampler_perf/mean_action_processing_ms': {'max': 0.15824491327459161,\n",
       "  'min': 0.14809612591754312,\n",
       "  'avg': 0.15329712818522218,\n",
       "  'last': 0.14809612591754312,\n",
       "  'last-5-avg': 0.14974641404248418,\n",
       "  'last-10-avg': 0.15274737428640334},\n",
       " 'sampler_results/sampler_perf/mean_env_wait_ms': {'max': 564.4020525205129,\n",
       "  'min': 548.712877484111,\n",
       "  'avg': 556.6603254657529,\n",
       "  'last': 564.4020525205129,\n",
       "  'last-5-avg': 555.3687472786706,\n",
       "  'last-10-avg': 555.8324444695049},\n",
       " 'sampler_results/sampler_perf/mean_env_render_ms': {'max': 0.0,\n",
       "  'min': 0.0,\n",
       "  'avg': 0.0,\n",
       "  'last': 0.0,\n",
       "  'last-5-avg': 0.0,\n",
       "  'last-10-avg': 0.0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.metric_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 14:56:06,383\tWARNING deprecation.py:46 -- DeprecationWarning: `rllib rollout` has been deprecated. Use `rllib evaluate` instead. This will raise an error in the future!\n",
      "2022-06-29 14:56:08,423\tINFO services.py:1470 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8267\u001b[39m\u001b[22m\n",
      "2022-06-29 14:56:09,753\tINFO trainer.py:2332 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2022-06-29 14:56:09,754\tINFO ppo.py:414 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2022-06-29 14:56:09,754\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 935, in setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 1074, in _init\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/env/utils.py\", line 54, in gym_env_creator\n",
      "    return gym.make(env_descriptor, **env_context)\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/gym/envs/registration.py\", line 200, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/gym/envs/registration.py\", line 104, in make\n",
      "    spec = self.spec(path)\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/gym/envs/registration.py\", line 131, in spec\n",
      "    raise error.Error(\n",
      "gym.error.Error: Attempted to look up malformed environment ID: b'compiler_gym'. (Currently all IDs must be of the form ^(?:[\\w:-]+\\/)?([\\w:.-]+)-v(\\d+)$.)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/bin/rllib\", line 8, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/scripts.py\", line 46, in cli\n",
      "    evaluate.run(options, rollout_parser)\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/evaluate.py\", line 348, in run\n",
      "    agent = cls(env=args.env, config=config)\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 870, in __init__\n",
      "    super().__init__(\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/tune/trainable.py\", line 156, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 950, in setup\n",
      "    self.workers = WorkerSet(\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 170, in __init__\n",
      "    self._local_worker = self._make_worker(\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 630, in _make_worker\n",
      "    worker = cls(\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 506, in __init__\n",
      "    self.env = env_creator(copy.deepcopy(self.env_context))\n",
      "  File \"/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/ray/rllib/env/utils.py\", line 56, in gym_env_creator\n",
      "    raise EnvError(ERR_MSG_INVALID_ENV_DESCRIPTOR.format(env_descriptor))\n",
      "ray.rllib.utils.error.EnvError: The env string you provided ('compiler_gym') is:\n",
      "a) Not a supported/installed environment.\n",
      "b) Not a tune-registered environment creator.\n",
      "c) Not a valid env class string.\n",
      "\n",
      "Try one of the following:\n",
      "a) For Atari support: `pip install gym[atari] autorom[accept-rom-license]`.\n",
      "   For VizDoom support: Install VizDoom\n",
      "   (https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md) and\n",
      "   `pip install vizdoomgym`.\n",
      "   For PyBullet support: `pip install pybullet`.\n",
      "b) To register your custom env, do `from ray import tune;\n",
      "   tune.register('[name]', lambda cfg: [return env obj from here using cfg])`.\n",
      "   Then in your config, do `config['env'] = [name]`.\n",
      "c) Make sure you provide a fully qualified classpath, e.g.:\n",
      "   `ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv`\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!rllib rollout ~/ray_results/PPOTrainer_2022-06-29_12-56-45/PPOTrainer_compiler_gym_7508e_00000_0_2022-06-29_12-56-45/checkpoint_000010/checkpoint-10 --run PPO --episodes 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.restore(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_agent_on_benchmarks(benchmarks):\n",
    "#     \"\"\"Run agent on a list of benchmarks and return a list of cumulative rewards.\"\"\"\n",
    "#     with make_env() as env:\n",
    "#         rewards = []\n",
    "#         for i, benchmark in enumerate(benchmarks, start=1):\n",
    "#             observation, done = env.reset(benchmark=benchmark), False\n",
    "#             while not done:\n",
    "#                 action = agent.compute_single_action(observation)\n",
    "#                 observation, _, done, _ = env.step(int(action))\n",
    "#             rewards.append(env.episode_reward)\n",
    "            \n",
    "#             print(f\"[{i}/{len(benchmarks)}] \")\n",
    "\n",
    "#     return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_rewards = run_agent_on_benchmarks(train_benchmarks)\n",
    "# test_rewards = run_agent_on_benchmarks(test_benchmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "# axs[0].title.set_text('Train rewards')\n",
    "# axs[0].plot(train_rewards, color=\"red\")\n",
    "# axs[0].plot(np.zeros_like(train_rewards), color=\"blue\")\n",
    "\n",
    "# axs[1].title.set_text('Test rewards')\n",
    "# axs[1].plot(test_rewards, color=\"green\")\n",
    "# axs[1].plot(np.zeros_like(test_rewards), color=\"blue\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e804d18dc74ce1dc9e76e68b7cf0aefb2bc0afdfbb2c1892ec3bac3a66589459"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('compiler_gym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
